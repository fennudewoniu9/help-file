衡量标准：TPS（每秒事务量，一般几百、好的上千）

0: MySQL历史
0: MVCC（Mutli Version Concurreny Control,多版本并发控制）
1: 登陆查询操作
2: 索引（常见问题优化）
3: 索引漫谈
4: 慢查询日志
5: 执行计划
6: 多表更新/主键
7: 公司级别的高可用 & 数据一致性 & 权限管理 & 加密/脱敏
8: 高可用（Mysql的日志体系）（ MGR - 异步 - 半同步 ）
9: 秒杀案例
10: 锁
11: 存储结构


0: MySQL历史
    1995年，MySQL 1.0发布，仅供内部使用。
    1996年，MySQL 3.11.1发布，直接跳过了MySQL 2.x版本。
    1999年，MySQL AB公司成立。同年，发布MySQL 3.23，该版本集成了Berkeley DB存储引擎。该引擎由Sleepycat公司开发，支持事务。在集成该引擎的过程中，对源码进行了改造，为后续可插拔式存储引擎架构奠定了基础。
    2000年，ISAM升级为MyISAM存储引擎。同年，MySQL基于GPL协议开放源码。
    2002年，MySQL 4.0发布，集成了后来大名鼎鼎的InnoDB存储引擎。该引擎由Innobase公司开发，支持事务，支持行级锁，适用于OLTP等高并发场景。
    2005年，MySQL 5.0发布，开始支持游标，存储过程，触发器，视图，XA事务等特性。同年，Oracle收购Innobase公司。
    2008年，Sun以10亿美金收购MySQL AB。同年，发布MySQL 5.1，其开始支持定时器（Event scheduler），分区，基于行的复制等特性。
    2009年，Oracle以74亿美金收购Sun公司。
    2010年，MySQL 5.5发布:InnoDB代替MyISAM成为MySQL默认的存储引擎;半同步复制;引入utf8mb4字符集、可用来存储emoji表情。
    2013年，MySQL 5.6发布:GTID复制;基于库级别的并行复制;mysqlbinlog可远程备份binlog;Online DDL/ALTER操作不再阻塞DML;Redo Log总大小的限制从之前的4G扩展至512G;EXPLAIN可查看DELETE/INSERT/REPLACE/UPDATE等DML(之前只支持SELECT)
    2015年，MySQL 5.7发布:组复制;InnoDB Cluster;多源复制;增强半同步（AFTER_SYNC）;在同一长度编码字节内、修改VARCHAR的大小只需修改表的元数据、无需创建临时表;InnoDB原生支持分区表，之前是通过ha_partition接口来实现的;原生支持JSON类型及众多JSON函数
    2018年，MySQL 8.0发布:PERFORMANCE_SCHEMA查询性能提升，其已内置多个索引;角色（Role）;资源组（Resource Groups），可用来控制线程的优先级及其能使用的资源，目前，能被管理的资源只有CPU
    # +------+-------------+-----------+-----------------+----------------+
    # | 版本  |   GA时间    | 最新小版本 | 最新小版本发布时间 | 产品支持结束时间 |
    # +------+-------------+-----------+-----------------+----------------+
    # |  5.1 | 2008-11-04  |  5.1.73   |    2013-12-03   |     2013-12    |
    # +------+-------------+-----------+-----------------+----------------+
    # |  5.5 | 2010-12-03  |  5.5.61   |    2018-07-27   |     2018-12    |
    # +------+-------------+-----------+-----------------+----------------+
    # |  5.6 | 2013-02-05  |  5.6.41   |    2018-07-27   |     2021-02    |
    # +------+-------------+-----------+-----------------+----------------+
    # |  5.7 | 2015-10-21  |  5.7.23   |    2018-07-27   |     2023-10    |
    # +------+-------------+-----------+-----------------+----------------+
    # |  8.0 | 2018-04-19  |  8.0.12   |    2018-07-27   |     2026-04    |
    # +------+-------------+-----------+-----------------+----------------+
    从表中的数据来看，
    1. 大概每3年会发布一个大的版本。
    2. 产品的支持周期一般是8年。
    3. 以为MySQL 5.5是老古董了，但官方仍然在不断更新。

0: MVCC（Mutli Version Concurreny Control,多版本并发控制）

Mysql隔离级别：
  ReadCommitted总是读取行的最新版本，如果行被锁定了，则读取该行版本的最新一个快照。
  Repeatable的隔离级别总是读取事务开始时的行数据。因此ReadCommitted会出现不可重复读，而Repeatable情况下不会。（事务开始后前后两个一样的查询sql之间另外一
  个事务提交了数据修改，Repeatable前后两次一样）

Mysql: 外键和锁为什么在高并发时效率低：
InnoDB存储引擎中对于一个外键列如果没有显示添加索引，引擎会自动添加一个索引，从而可以避免表锁；但插入或者更新子表时会锁定父表，造成并发效率低。


Mariadb:
cd /usr/local/opt/mariadb/bin
./mysql.server start

1: 登陆查询操作
    ============================================================
    新增用户及授权时一定要在mysql库里操作
    ============================================================
    登陆数据库:
      mysql -h127.0.0.1 -uroot -p123456 --port=3306;
      mysql -h172.24.0.11 -um_jingcca -pBw6u7q --port=3306;

    查询数据库信息:
      status;

    列出当前Schema中所有的database:
      show databases; #select database();

    使用某一个数据库: 
      use database_name;

    列出数据库中所有的table:
      所有表: show tables [FROM db_name];
      查看表结构: desc table_name;   show create table table_name;
      查看表状态: show table status like 'table_name';
      查看字段: select column_name,column_comment from information_schema.columns where table_name = 'table_name';
      
      select * from book \G; #以列的形式显示结果集；

    查看和日志有关的变量:
    show variables like '%log%';


2: 索引
    索引／查询优化器的原理: http://www.ituring.com.cn/article/986
    索引查询快的原因：
        - 索引本身占用的磁盘空间比原来的表更少，导致扫描磁盘的块数少
        - 索引是有序的数据结构，查询算法（二分法）可以提高查询速度
    优化建议:
      * 一般在where、group by、order by、on从句中出现的列上加索引
      * 索引字段越小越好
      * 离散度高的字段放在联合索引的前面。#离散度：唯一值的个数（count唯一值大的）
        # 查询优化器会在离散度小于记录数的30%时放弃索引，实际上等于索引纯粹只会浪费空间。
      * 同一个字段「尽量」不要重复、冗余建立索引
      * 根据离散度、选择度优化，根据选择度优化步骤：
        选择度优化步骤:
          - show index from table_name   确定第三步使用哪一个索引（优先唯一索引）
          - show table status like table_name   确定第三步limit使用的数量
          - select count(*) from (select cl1 from table_name FORCE INDEX(uniq_id) order by cl2 desc limit 10000) table_name where cl1 = '123123'
            查询出来的值除以limit的值就是选择度，选择度最大1，越大越好。

    分析sql：（information_schema下执行）
    select
      a.TABLE_SCHEMA AS '数据名',
      a.TABLE_NAME AS '表名',
      a.INDEX_NAME AS '索引1',
      b.INDEX_NAME AS '索引2',
      a.COLUMN_NAME as '重复列名'
    from STATISTICS a JOIN STATISTICS b ON
      a.TABLE_SCHEMA = b.TABLE_SCHEMA
      AND a.TABLE_NAME = b.TABLE_NAME
      AND a.SEQ_IN_INDEX = b.SEQ_IN_INDEX
      AND a.COLUMN_NAME = b.COLUMN_NAME

    查看索引: show index from table_name; 
    分析工具: pt-duplicate-key-checker 
    未使用索引: MariaDB：INDEX_STATISTICS表可以分析，Mysql只能通过工具
    冗余索引: 用固定的SQL分析查找。或者pt-duplicate-key-checker工具，可给出修改建议。
    不用的索引: 慢查询+pt-index-usage工具，主从结构时要分析所有DB。

    常见问题优化:
      Max(name): 使用name索引，全覆盖索引，执行时间永远恒定
      子查询 Vs 链接查询: 有时需要用链接查询替换子查询，以规避临时表、文件排序；有时需要用子查询 + Group by替换链接查询，以规避临时表。
      limit: 常伴随order by操作，会增加大量的 I/O 操作。
             优化: 1.limit之前用主键或者索引列order by一下。  2.记录上次所描的列数，作为下次的where条件，以减少每次扫描的行数。
      in VS exists: mysql中的in语句是把外表和内表作hash 连接，而exists语句是对外表作loop循环，每次loop循环再对内表进行查询，
             select * from A exists (select * from B a.id=b.id)，A是外表B是内表。一直大家都认为exists比in语句的效率要高，这种说法其实是不准确的。这个是要
             区分环境的。 #http://www.manongjc.com/article/981.html

3: 索引漫谈
   Q：为什么选择B+而不是哈希表、二叉树或者BTree:
   A：Mysql选用B+树这种数据结构作为索引，可以提高查询索引时的磁盘IO效率( 一个节点默认一页，Mysql的Innodb引擎中一页的默认大小是16k字节（而不是16k比特-bit）（如果
      操作系统中一页大小是4k，那么Mysql中1页=操作系统中4页） )，并且可以提高范围查询的效率(原因在于B+树中的非叶子节点会冗余一份在叶子节点中，并且叶子节点之间用指针
      相连。另，哈希表不支持范围查找)，并且B+树里的元素也是有序的。
      PS: show variables like 'innodb_page_size'结果是16384，单位是字节。

       PS：为什么有人平时说B+非叶子节点不存数据:
       通常我们认为B+树的非叶子节点不存储数据，只有叶子节点才存储数据；而B树的非叶子和叶子节点都会存储数据，会导致非叶子节点存储的索引值会更少，树的高度相对会比B+树
       高，平均的I/O效率会比较低，所以使用B+树作为索引的数据结构，再加上B+树的叶子节点之间会有指针相连，也方便进行范围查找。

    Q：主键索引vs辅助索引:
    A：InnoDB中主键索引的叶子节点的数据区域存储的是数据记录，辅助索引存储的是主键值。Innodb中的主键索引和实际数据时绑定在一起的，也就是说Innodb的一个表一定要有主键
       索引，如果一个表没有手动建立主键索引，Innodb会查看有没有唯一索引，如果有则选用唯一索引作为主键索引，如果连唯一索引也没有，则会默认建立一个隐藏的主键索引（用户
       不可见）。另外，Innodb的主键索引要比MyISAM的主键索引查询效率要高（少一次磁盘IO），并且比辅助索引也要高很多。所以，我们在使用Innodb作为存储引擎时，我们最好：
       a.手动建立主键索引
       b.尽量利用主键索引查询

    Q：为什么一个节点1页(16k)就可以了:
    A：假设我们一行数据大小为1K，那么一页就能存16条数据，也就是一个叶子节点能存16条数据；再看非叶子节点，假设主键ID为bigint类型，那么长度为8B字节（int是4B字节），
       指针大小在Innodb源码中为6B，一共就是14B，那么一页里就可以存储16K/14=1170个(主键+指针)，那么一颗高度为2的B+树能存储的数据为：117016=18720条，一颗高度为3
       的B+树能存储的数据为：11701170*16=21902400（千万级条）。所以在InnoDB中B+树高度一般为1-3层，它就能满足千万级的数据存储。在查找数据时一次页的查找代表一次IO
       ，所以通过主键索引查询通常只需要1-3次IO操作即可查找到数据。所以也就回答了我们的问题，1页=16k这么设置是比较合适的，是适用大多数的企业的，当然这个值是可以修改的
       ，所以也能根据业务的时间情况进行调整。

    Q：为什么索引字段不建议太长:
    A：（1）MyISAM的索引与数据分开存储，索引叶子存储指针，主键索引与普通索引无太大区别；
       （2）InnoDB的聚集索引和数据行统一存储，聚集索引存储数据行本身，普通索引存储主键；
       （3）InnoDB不建议使用太长字段作为PK（此时可以加入一个自增键PK）浪费内存和缓存空间，MyISAM则无所谓；
    PS：MyISAM的索引与记录存储分离，有单独的区域存储行记录，PK是非聚集索引。

    Q：为什么在并发插入量比较大的时候，比较适合使用MyISAM呢？不会因为表锁频繁冲突而导致吞吐量降低吗:
    A：MyISAM的索引与记录存储分离，有单独的区域存储行记录，PK是非聚集索引。MyISAM表，如果数据文件(data file)紧密存储，中间没有空闲块(free blocks)，数据总是插入
       到数据文件的尾部(end)，就如同追加日志一样，性能很高，此时的并发insert与select是不加锁的(lock free)。MyISAM表，如果数据文件(data file)中间有空洞(hole)
       （删除产生的），上述机制会失效，直到空洞被新数据填满，又会启用不加锁机制。
 

4: 慢查询日志
    记录的是整个数据库服务器的信息，而不是单个的schema信息

    查看mysql是否开启慢查询日志: show variables like 'slow_query_log';

    开启慢查询日志: set global slow_query_log=on;
    查看日志存储路径: show variables like 'slow_query_log_file';
    设置日志存储路径: set global show_query_log_file=‘/home/mysql/sql_log/mysql-slow.log’ #该目录是exit数据库后宿主机的位置

    记录【没有使用索引】的查询sql到慢查询日志: set global log_queries_not_using_indexes=on;

    记录查询超过多少秒的sql到日志中: show variables like 'long_query_time';
    设置时间: set global long_query_time=1; # 一般1秒很大，正常是100ms

    日志中记录的每一条记录信息格式如下: 
                                - # Time: 170716 13:51:27
                                - # User@Host: root[root] @ localhost []
                                - # Thread_id: 13  Schema: work-product  QC_hit: No
                                - # Query_time: 0.000208  Lock_time: 0.000044  Rows_sent: 48  Rows_examined: 48
                                - # Rows_affected: 0
                                - SET timestamp=1500184287;
                                - select * from shb_classes;

    #以上设置需要退出、进入后才能show到更新后的值；   

    慢查询工具: 
            - mysqldumpslow:
              不需要安装，mysql自带的；但是功能较少
                command: mysqldumpslow -t 4 /tmp/mysql-slow.log
                         mysqldumpslow -t 4 /tmp/mysql-slow.log | more # 通过more工具查看

            - pt-query-digest: 
              分析慢查询日志文件比mysqldumpslow更丰富 #http://blog.csdn.net/seteor/article/details/24017913
                输出到文件: pt-query-digest show-log > slow_log.report
                输出到数据库表: pt-query-digest show.log -review \
                h=127.0.0.1,D=test,p=root.P=3306,u=root,t=query_review \
                --create-reviewtable \
                --review-history t=hostname_show

                pt-query-digest分析慢查询日志文件比mysqldumpslow更丰富: 
                    1.显示日志的时间范围,以及总的sql数量.
                    2.表的统计信息sql响应时间和执行次数。
                    3.具体的sql
                解决: 
                    1.查询时间长,查询次数多
                    2.IO大的sql,分析Rows Examine项,扫描的行数
                    3.未命中索引的sql,分析Rows Examine与Rows send发送的行数的对比

            - pt-query-digest安装: #http://blog.csdn.net/wireless_com/article/details/51615627
              1.http://www.percona.com/downloads/percona-toolkit
              2.tar xvfz percona-toolkit-2.2.7.tar.gz
              3.cd percona-toolkit-2.2.17
              4.perl Makefile.PL
              5.sudo perl -MCPAN -e "install DBI"
              6.sudo perl -MCPAN -e "install DBD::mysql" #`ld: library not found for -lssl` -> The solution was:xcode-select --install
              7.perl Makefile.PL --mysql_config=/usr/local/opt/mariadb/bin/mysql_config
              8.make
              9.make install


5: 执行计划
    MariaDB [dalin]> explain select * from book;
    # +------+-------------+-------+------+---------------+------+---------+------+------+-------+
    # | id   | select_type | table | type | possible_keys | key  | key_len | ref  | rows | Extra |
    # +------+-------------+-------+------+---------------+------+---------+------+------+-------+
    # |    1 | SIMPLE      | book  | ALL  | NULL          | NULL | NULL    | NULL |    4 |       |
    # +------+-------------+-------+------+---------------+------+---------+------+------+-------+

    table: 显示这一行的数据是关于哪张表的
    type: 这是重要的列,显示连接使用了何种类型。从最好到最差的连接类型为const、eq_reg、ref、range、index和ALL
    possible_keys: 显示可能应用在这张表中的索引。如果为空，没有可能的索引。
    key: 实际使用的索引。如果为NULL，则没有使用索引。
    key_len: 使用的索引的长度。在不损失精确性的情况下，长度越短越好。
    ref: 显示索引的哪一列被使用了,如果可能的话，是一个常数
    rows: MYSQL认为必须检查的用来返回请求数据的行数
    extra列需要注意的返回值: 
      Using filesort: 看到这个的时候，查询就需要优化了。MYSQL需要进行额外的步骤来发现如何对返回的行排序。它根据连接类型以及存储排序键值和匹配条件的全部行的行指针来排序全部行
      Using temporary: 看到这个的时候，查询需要优化了。这里，MYSQL要创建一个临时表来存储接口，这通常发生在对不同的列表进行ORDER BY上，而不是GROUP BY上。
      # 注意: 尽量不要使用临时表、文件排序。
      filesort一般是有orderby引起的，对于datetime类型的需要和where条件中的一个一起加一个联合索引。
      优化前： 
        ![image](img/BeforeAddIndex.jpeg)
      优化后： 
        ![image](img/AfterAddIndex.jpeg)

    优化:  # 衡量标准：TPS（每秒事务量，一般几百、好的上千）  JingKa的最差的0.31s扫描38万数据
         --------------优化-表扫描/索引扫描-------------
         -I/O：最根本的优化，RowsSent-RowsExamine的差

         慢查询: pt_query_disgest工具
         -table: 是否使用了表扫描
         -rows: 扫描的行数
         -extra: using filesort/temporary文件/临时表 数据转储
         -type: const、eq_reg、ref、range、All（最慢）
         -count()优化: *和具体字段不一样，区别在于null的
         -Max()优化: 不查表、只查index的sql-覆盖索引
         -子查询优化: 转化成join的时可能会1对多,用distinct
         -groupby优化: 子查询缩小范围，同时把聚合函数放子查询里；尽量！可以减少临时表等方式。
         limit优化: 主要思想是避免过多行数的扫描。1.主键排序可以减少I/O操作；2.记录上次扫描到的id，从这个id开始可以固定扫描行数（缺点：逐渐一定要顺序增长和连续，如果不是可见建立辅助列）。
     
         -------------------设计优化-------------------
         范式化（第三范式化）
         反范式化（字段冗余）
         垂直拆分
         水平拆分
         字段: int优于time优于varchar优于text
         索引: 散列值/离散度高（count唯一值大的）、小字段、不要字段冗余；离散度高的放在联合索引前面。过多的index不仅影响写，还增加查时的分析时间--删除重复和多余的index。
         选择度: 索引的可选择度指的是索引列包含的唯一值数量与索引列所有数据行数的比例(T),一个高选择度的列索引会使MySQL在检索时过滤掉更多的数据,最好的一种情况是唯一索引,它的可选择度为1
                select count(*) from (select cl1 from table_name FORCE INDEX(uniq_id) order by cl2 desc limit 10000) table_name where cl1 = '123123';
         冗余索引: 用固定的SQL分析查找。或者pt-duplicate-key-checker工具，可给出修改建议。
         不用的索引: 慢查询+pt-index-usage工具，主从结构时要分析所有DB。

    主从同步:  
         ![image](img/mysqlBinLog-sync.png)



6: 多表更新/主键
    update table1 INNER_JOIN table2 on t1.cln = t2.cln set t1.cln_1 = t2.cln_2; #参考table2更新table1

    ALTER TABLE author DROP PRIMARY KEY;
    ALTER TABLE author modify id int(11) NOT NULL AUTO_INCREMENT PRIMARY KEY;


 
7: 公司级别的高可用 & 数据一致性 & 权限管理 & 加密/脱敏
  7.1.高可用:
    一般使用MHA架构，主从切换10s左右，主宕机后从切换大概30s~60s。mysql5.7之后采用了MGR的架构以保证数据不丢失。(具体参考8.高可用)
    一般一天一备份，binlog日志也全部备份。七天之内本机保留。7~15天的数据一般放到HDFS保留。15天之后的数据一月一备份。且备份文件在生成的时候进行有效性校验，校验不通过时会丢
    掉，丢掉后通过上一备份点加binlog的方式恢复。
  7.1.一致性:
      Mysql 5.7复制功能（mysql复制集群）
      Mysql复制: 异步（默认方式，半同步也是异步也有延迟）（受主的写的频率影响：主的写是并发的，而log操作同步到salve是单线程的）
     
      Mysql的复制是基于BinLog的: （打开binglog性能会下降60%左右；生产上数据加密功能，binlog打开，一次读两次写，大概133行/秒）
        三种日志格式:
          Statement: 存储SQL语句，文件小，某些函数可能会造成主从不一致，不建议使用
                Row: 存储event数据，存储日志量大，但是不能很直接的进行读取
              Mixed: 介于Row和Statement之间，对于不确定的操作使用Row记录，如果每天数据操作量很大，产生的日志比较多，可以考虑选择mixed格式。
     
      部分复制: mysql的复制可以是整个数据库实例或者是某个库，某个表.
               主要通过master的binlog-do-db哪些要记录日志  -ignore-db哪些不用记录日志，slave可以通过replicate -do-db.
               -ignore-db...等复制命令进行同步进行控制.建议一般是通过slave端进行控制，可以更精细化的控制,master建立完整的日志操作。
 
      复制类型:
          二进制日志的复制、5.5之前是基于二进制的日志类型复制，但主从切换时无法确定具体的切换点。使用gtid基于全局事务的复制，每一个事务对应一个全局标识，可以很容易的找到复制
          点。为高可用带来很大方便。mysql5.7开始支持半同步优化主从复制，通过安装一些插件，日志先入的方式，等待某一个或者某几个slave返回确认ok后进行真正的事务提交。
  7.1.权限管理（权限分级）:
    运维DBA：堡垒机才能登陆，且所有操作都有录屏。开发DBA：增删改权限。自动化运维：自动化平台，限定权限。数据部/Miss：一般只有查询权限。
  7.1.加密脱敏:

8: 高可用（Mysql的日志体系）（ MGR - 异步 - 半同步 ）
  MySQL通过复制（Replication）实现存储系统的高可用。目前，MySQL支持的复制方式有: 异步复制（Semi Sync）、半同步复制（Semi Sync）、全同步复制（Fully syn Sync）；区别在
  于主库在执行完客户端提交的事务后，是否等待至少一个从库接收到并写到relay log中才返回给客户端，及从库和返回给客户端的先后顺序。默认情况下主库的日志落盘后主库才返回客户端。在
  5.7.17推出了组复制（mysql group replication，简称MGR）若干个点组成一个组，根据分布式一致性协议（Paxos的变体）多数同意后才能提交事务；MGR确保大多数节点都能收到日志，多
  写的模式下所有节点都能卸乳，通过一致性协议实现源自消息和全局有序消息。但MGR仅支持InnoDB表，每个表必须有一个主键；必须打开GTID特性，日志格式必须设置为ROW；目前一个MGR集群
  最多支持9个节点；不支持外键和save point特性，无法做全局间的约束检测与部分回滚。 #http://www.cnblogs.com/luoahong/articles/8043035.html
  8.1: 日志体系:
    事务的简化过程:
    ————————————————
      假设有A、B两个数据，值分别为1,2，现在修改为3、4
      1. 事务开始。
      2. 记录A=1到undolog。
      3. 修改A=3。
      4. 记录A=3到redolog。
      5. 记录B=2到undolog。
      6. 修改B=4。
      7. 记录B=4到redolog，将redolog写入磁盘。
      8. 事务提交。
    ————————————————
    结论: 修改前的数据放在 undolog 用于回滚；修改后的数据放到 redolog 用于重试、修复。
        binlog: redolog 是Innodb实现的物理日志，一旦涉及到多种存储引擎，无法进行重做。binlog 记录下所有数据的更改，可用于本机数据恢复和主从同步。
        relylog中继日志: 主节点将binlog写入本地，主从节点同步增量binlog时，会用单独进程将binlog 拷贝至本地 relaylog中。从节点定时重放relaylog。
        根据数据写入主和从的先后关系: undolog -- redolog(binlog) -- relylog

    Mysql的复制是基于BinLog的:
        三种日志格式:
        Statement: 存储SQL语句，文件小，某些函数可能会造成主从不一致，不建议使用
              Row: 存储event数据，存储日志量大，但是不能很直接的进行读取
            Mixed: 介于Row和Statement之间，对于不确定的操作使用Row记录，如果每天数据操作量很大，产生的日志比较多，可以考虑选择mixed格式。
  
  8.2: 主从同步策略: # mysql5.7以前是MHA架构（主从），5.7以后是MGR架构（集群）
    异步复制（Asynchronous replication）:
          异步复制，主库将事务 Binlog 事件写入到 Binlog 文件中，此时主库只会通知一下 Dump 线程发送这些新的 Binlog，然后主库就会继续处理提交操作，而此时不
          会保证这些 Binlog 传到任何一个从库节点上。
    全同步复制（Fully synchronous replication）:
          全同步复制，当主库提交事务之后，所有的从库节点必须收到、APPLY并且提交这些事务，然后主库线程才能继续做后续操作。但缺点是，主库完成一个事务的时间会被
          拉长，性能降低。
    半同步复制（Semisynchronous replication）:
          半同步复制，是介于全同步复制与全异步复制之间的一种，主库只需要等待至少一个从库节点收到并且 Flush Binlog 到 Relay Log 文件即可，主库不需要等待所
          有从库给主库反馈。同时，这里只是一个收到的反馈，而不是已经完全完成并且提交的反馈，如此，节省了很多时间。

  8.3: MySQL 5.7极大的提升了半同步复制的性能:
    5.6版本的半同步复制，dump thread 承担了两份不同且又十分频繁的任务：传送binlog 给slave ，还需要等待slave反馈信息，而且这两个任务是串行的，dump thread 
      必须等待 slave 返回之后才会传送下一个 events 事务。dump thread 已然成为整个半同步提高性能的瓶颈。在高并发业务场景下，这样的机制会影响数据库整体的TPS 。
    5.7版本的半同步复制中，独立出一个 ack collector thread ，专门用于接收slave 的反馈信息。这样master 上有两个线程独立工作，可以同时发送binlog 到slave ，
      和接收slave的反馈。


9: 秒杀案例: #http://www.cnblogs.com/clphp/p/6398667.html
  Step1:
    1.接下来，每次插入前执行以下以下操作检查一下是否超卖即可：
      select sum(buy_count) from UserProduct where product_id = ?
    2.最后还要检查一下这个用户是否购买过：
      select count(*) from UserProduct where user_id = ? and product_id = ?
    3.全都没问题了就插入数据：
      insert into UserProduct (user_id, product_id, buy_count) values (?, ?, ?)

  Step2-优化:
    3的问题-保证单用户不会重复购买：加上唯一索引(user_id, product_id)

  Step3-优化: （一般秒杀场景够用）
    1、2的问题-解决超卖问题：1的SQL加上for update，三个语句放在同一个事物中 
    # 为了for update是行锁而不是表锁，需要在product_id上加一个索引

  Step4-优化: （超大规模秒杀场景够用）
    Step3的优化会影响性能。
    对策：去掉事物，同时把1的语句换成如下：
    update Product set buy_count = buy_count+? where id = ? and buy_count+? <= buy_max
    
  最终方案:
    1.update Product set buy_count = buy_count+? where id = ? and buy_count+? <= buy_max
    2.insert into UserProduct (user_id, product_id, buy_count) values (?, ?, ?) #有唯一索引
    同时，如果第二步失败了（重复购买），需要逆向执行一句1的SQL，把库存还回去。

10: 锁
    通常情况下，下列四种情况，表锁会优于行锁：
    * 该表的大多数语句均为读
    * 该表的语句是读和写的混合，其中写是对单行的更新或删除，可通过一次按键读取来获取：
        UPDATE tbl_name SET column=value WHERE unique_key_col=key_value;
        DELETE FROM tbl_name WHERE unique_key_col=key_value;
    * SELECT与并发INSERT语句结合使用，很少有 UPDATE or DELETE语句
    * 在整個表中执行很多扫描或GROUP BY操作时沒有任何写。
    PS：如果业务经常读写表中很大一部分数据时，表锁会更快，因为此时只涉及一个锁，而不是同时管理N多个锁；
    Mysql不同维度下锁的分类: https://cloud.tencent.com/developer/article/2431018
    Mysql行锁升级成表锁，原因是有索引会加在具体的行上，没有索引是加的是全表: https://blog.csdn.net/qq_39408664/article/details/118937047

11: 存储结构
    逻辑存储结构:
    表空间->段空间->区空间->页空间->行
    表空间: InnoDB存储引擎逻辑结构的最高层，所有数据都是存储在表空间中。包含数据、索引、插入缓冲、其他如Undo信息等，rollback后Undo信息不会被清理会被标记成不需要，新的Undo信息会覆盖这些
    段空间: 表空间由各个段组成，常见的段有数据段、索引段、回滚段等。InnoDB存储引擎表是索引组织的，因此数据即索引，索引即数据
    区空间: 区由64个连续的页组成，每个页16k，即每个区1MB，对于大数据段，InnoDB存储引擎每次最多允许申请4个区，以此来保证数据的顺序性能
    页空间: 每个页16k，也被称为块，是InnoDB磁盘管理的最小单位。包含数据页、Undo页、系统页、事务页、插入缓冲位图页、未压缩的二进制大对象页、压缩的二进制大对象页
    行空间: InnoDB存储引擎是面向行的，也就是说数据的存放是按行进行存放的。每个页存放的行记录是有硬性的规定的，最多允许7992个。记录以行的形式存储，5.1开始存在Compact和Redundant两种格式
            - 一行中所有varchar的总长为65535（Compact格式下最多两个字节表示一列，2个字节16位，2的16次方65536，再减去Null标识位）
            - 一行最多1023个列（Redundant格式下表示列数量的n_fields固定10位）
            - 默认是Compact格式，Rdundant是为了兼容老的

    物理存储结构:
    InnoDB表由共享表空间、日志文件组（更准确的说是Redo文件组）、表结构定义文件组成。


    InnoDB设计是支持行锁，同时支持多粒度的锁，支持行级锁和表锁同时存在；为了支持不同粒度上加锁InnoDB支持一种额外的锁方式--意向锁，意向锁是表级锁，为了在一个事务中揭示下一行将被请求的锁类型，意向锁不会阻塞初全表扫以外的任何请求。
    InnoDB引擎关于锁的机制是：当发生死锁的时候会选择事务权重值最小的进行回滚
















