---------------------------------------------------------------------------------------------------------------------------------
数据类型（指的是value的值）: 字符串、哈希（类似map）、列表、集合、有序集合；分别用于处理的场景：
  字符串：一个键值对；可以针对key增删查
  哈希：一个对象拥有多个属性；可以单独获取所有属性的key值和所有属性的value值，可以针对key值加减对应的value，可以添加删除key值，可以hlen获取属性的数量
  列表：类似一个队列模型；可以左右两头操作，可以push时key存在再进行add元素，可以pop-同时进行获取和remove操作，可以根据index获取、覆盖值，可以在index前后add值，可以范围获取，可以len获取元素的数量
  集合：类似数学模型里的两个唯一元素的集合；元素唯一，可以获取两个集合的合集、交集、一个集合不在另一个集合里的元素并存储到新的集合（分别对应两个圆的合、交、非），可以获取元素数量，可以随机获取n个元素，可以移动某个元素到另一个集合
  有序集合：集合元素添加时附带一个分值；可以获取元素数量，可以获取分值区间内的数量，可以添加一个带分值的元素（分值一样ascci大的index大），可以删除一个元素（集合不存在不报错），可以获取元素的index值、分值、排名（分值、index(0开始)由小到大，排名由大到小）
---------------------------------------------------------------------------------------------------------------------------------


1: 什么是redis
2: 版本发展历史
3: 三大问题，并发竞争key的解决方案--高并发快的3大原因--为什么Redis是单线程的
4: 分布式集群架构
5: 淘汰策略
6: Memcache与Redis的区别都有哪些
7: Redis 常见的性能问题都有哪些
8: redis 最适合的场景
9: Redis 分别提供了 RDB 和 AOF 两种持久化机制
10: 命令: #在线命令测试: http://try.redis.io/
11: 修改查询逻辑：MOVED 重定向
12: Redis集群内部通讯协议：gossip 协议
13: Redis灵魂三问


1: 什么是redis:
	- Redis 是一个基于内存的高性能key-value数据库，支持保存多种数据结构，定期通过异步操作把数据库数据flush到硬盘上进行保存。
  - 单个value的最大限制是1GB，不像memcached只能保存1MB的数据，也可以对存入的Key-Value设置expire时间
  - 意大利科学家用C语言开发的
    读: 11w/s
    写: 8.12w/s

2: 版本发展历史: 
    主从--哨兵--集群，三个大的阶段。
    主从复制是为了数据备份，哨兵是为了高可用，Redis主服务器挂了哨兵可以切换，集群则是为了解决单机容量有限问题，搞多个分散压力。
    Reids先是主从（切换需要人工干预），2.8之后出现了哨兵（每一秒发送master和slave的心跳ping，但是每个节点都存全量数据，内存利用率低），3.0之后出现了集群（solt）。

3: 三大问题: 
      1.并发竞争key的解决方案？
      2.高并发快的3大原因？
      3.为什么Redis是单线程的？
   答案:
      1.单线程不存在并发问题，但是使用jedis的时候1、2、3、4四次顺序更新最终的结果可能是3；可以使用分布式锁（先到先写）和时间戳（落后的时间不更新）解决。
      2.redis是基于内存的，内存的读写速度非常快；redis是单线程的，省去了很多上下文切换线程的时间；redis使用多路复用技术，可以处理并发的连接。非阻塞IO 内部实现采
        用epoll，采用了epoll+自己实现的简单的事件框架。epoll中的读、写、关闭、连接都转化成了事件，然后利用epoll的多路复用特性，绝不在io上浪费一点时间。
      3.因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地
        采用单线程的方案了。

4: 分布式集群架构:
  - Master会将数据同步到slave，而slave不会将数据同步到master。Slave启动时会连接master来同步数据。这是一个典型的分布式读写分离模型。我们可以利用master来插入数
    据，slave提供检索服务。这样可以有效减少单个机器的并发访问数量
  - 为了避免Master DB的单点故障，集群一般都会采用两台Master DB做双机热备
  PS: 读写分离架构的缺陷在于，不管是Master还是Slave，每个节点都必须保存完整的数据，如果在数据量很大的情况下，集群的扩展能力还是受限于单个节点的存储能力，而且对于
  Write-intensive类型的应用，读写分离架构并不适合。

5: 淘汰策略:
  MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据
  参考：mac上的《京东毫秒级热key探测框架设计与实践，已实战于618大促》《京东开源热key探测（JD-hotkey）中间件单机qps 2万提升至35万实录》
  # 数据：实时（准实时，可配置1-500ms内）探测系统运行中产生的热key，每秒可接收N台服务器发来的40多万个待测key，并计算完毕其中的35万左右。实测可每秒稳定计算30万，
  #      极限计算37万，超过的量会进入队 列等待。当热key产生后，对该业务集群所有长连接的服务器进行key推送，每秒可稳定推送10-12万次（毫秒内送达）。
  #      注意，推送是和接收30万key并行的，也就是进和出加起来吞吐量在40多万每秒。
  # 原来：核心是把这个问题转化成了一个由work集群承接的分布式的、简单的加法问题。
  #《京东毫秒级热key探测框架设计与实践，已实战于618大促》可以看到该框架没有依赖于任何定制化的组件，与redis更是毫无关系，核心就是靠netty连接，client端从etcd获取
  #   热key的判断规则，client根据规则送出待测key，然后由各个worker完成分布式计算，算出热key后利用netty和client的长链接，就直接推送到client端，非常轻量级；其
  #   中，服务端的计算使用的是disruptor（百万并发框架disruptor，可以参考2.1.1.Linux IO-NIO-异步非阻塞Netty.txt）
  #《京东开源热key探测（JD-hotkey）中间件单机qps 2万提升至35万实录》京东hotkey框架（JD-hotkey）是京东app后台研发的一款高性能热数据探测中间件，用来实时探测出系
  #   统的热数据，并将热数据毫秒内推送至系统的业务集 群服务器的JVM内存。以下统称为"热key"。经过三次调优从最初2w的qps变成了25w的qps，第三次调优的时候取消了号称百
  #   万并发的disruptorArrayBlockQueue替代了，因为：disruptor采用ringbuffer环形队列，如果生产消费速率相当情况下，理论上读写均无锁，是生产消费模型里理论上性能
  #   最优的。然而，一切都要靠场景和最 终成绩来说话，网上抛开了这些单独谈框架性能其实没有什么意义。第四次优化是把netty中的fastjson序列化方式变成了protobuf，最终
  #   是35w的qps。（fastjson和protobuf在30w的两级下能差300-500ms）
  # 补充：服务端的逻辑：netty默认开启cpu核数*2个线程，作为netty的工作线程，用于接收几千台机器发来的key，接收到待测key后，全部写入到disruptor的生产者线程，生产
  # 者是单线程。之后disruptor同样是cpu核数*2个消费者线程，每个消费者都重复消费每条发来的key。这里很明显的问题，大家都能看到，disruptor为什么要重复消费每个key？ 
  # 因为当初的设想是将同一个key固定交给同一个线程进行累加计算，以避免多线程同时累加同一个key造成数量计算错误。所以每个消费者线程都全部消费所 有的key，譬如8个线程，
  # 线程1只处理key的hash值为1的，其他的return不处理。这样看似消费了所有的key，但是仅仅计算了与自己hash值匹配的key。
  相关知识：redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。redis 提供 6种数据淘汰策略：
    - voltile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
    - volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
    - volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
    - allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰
    - allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰
    - no-enviction（驱逐）：禁止驱逐数据

6: Memcache与Redis的区别都有哪些:
  - 存储(持久化)方式
    Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。
    Redis有部份存在硬盘上，这样能保证数据的持久性。
    AOF／数据库快照两种，参考8

  - 数据支持类型
    Memcache对数据类型支持相对简单。
    Redis有复杂的数据类型。

  - 使用底层模型不同
    它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。
    Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。

  - value大小
    redis最大可以达到1GB，而memcache只有1MB

7: Redis 常见的性能问题都有哪些？如何解决:
  - Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。
  - Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。Master最好不要做任
    何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。
  - Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。
  - Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内
  - 除了超时还有什么一致性维护策略？设置超时；更安全的是先更新DB再更新redis，遇到redis失效、且读发生在update db之前、且读的时间长于写的时间这样的几率很小，如果
    想避免这种小概率事件，可以使用分布式事务解决。　　　

8: redis 最适合的场景: #http://www.cnblogs.com/qunshu/p/3196972.html
  - 根据与Memecache的区别确定
  - 会话缓存（Session Cache）：购物车信息，优势在于支持持久化
  - 全页缓存（FPC）：提高网页加载速度
  - 队列：因为提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。就类似于本地程序语言（如Python）对 list 的 push/pop 操作。
    如果你快速的在Google中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用Redis创建非常好的后端工具，以满足各种队列需求
    。例如，Celery有一个后台就是使用Redis作为broker，你可以从这里去查看
  - 排行榜/计数器：集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，只需执行一下命令即可：
    ZRANGE user_scores 0 10 WITHSCORES

9: Redis 分别提供了 RDB 和 AOF 两种持久化机制:
  - RDB 将数据库的快照（snapshot）以二进制的方式保存到磁盘中
  - AOF 则以协议文本的方式，将所有对数据库进行过写入的命令（及其参数）记录到AOF文件（使用网络通讯协议的格式来保存），以此达到记录数据库状态的目的。

    * AOF:
      1.模式:
        - 不保存（AOF_FSYNC_NO）
          # 每次调用 flushAppendOnlyFile 函数， WRITE 都会被执行， 但 SAVE 会被略过
        - 每一秒钟保存一次 （AOF_FSYNC_EVERYSEC）
          # 写入操作由主进程执行，阻塞主进程。保存操作由后台子进程调用的，不直接阻塞主进程，但保存操作完成的快慢会影响写入操作的阻塞时长。
            # - 子进程进行 AOF 重写期间，主进程可以继续处理命令请求。
            # - 子进程带有主进程的数据副本，使用子进程而不是线程，可以在避免锁的情况下，保证数据的安全性。
          # 具体可能不是每秒一次，还要看flushAppendOnlyFile 函数时 Redis 所处的状态有关（子线程是否正在执行 SAVE）
        - 每执行一个命令保存一次（AOF_FSYNC_ALWAYS）
          # 每次执行完一个命令之后， WRITE 和 SAVE 都会被执行

      2.同步命令到 AOF 文件的整个过程可以分为三个阶段:
        命令传播：Redis 将执行成功的命令、命令的参数、命令的参数个数等信息发送到 AOF 程序中。
        缓存追加：AOF 程序根据接收到的命令数据，将命令转换为网络通讯协议的格式，然后将协议内容追加到服务器的 AOF 缓存中。
        文件写入和保存：AOF 缓存中的内容被写入到 AOF 文件末尾，如果设定的 AOF 保存条件被满足的话， fsync 函数或者 fdatasync 函数会被调用，将写入的
        内容真正地保存到磁盘中。

      3.性能:
            模式            WRITE 是否阻塞？   SAVE 是否阻塞？     性能                    停机时丢失的数据量
        AOF_FSYNC_NO            阻塞              阻塞           高        操作系统最后一次对 AOF 文件触发 SAVE 操作之后的数据。
        AOF_FSYNC_EVERYSEC      阻塞              不阻塞         中                  一般情况下不超过 2 秒钟的数据。
        AOF_FSYNC_ALWAYS        阻塞              阻塞           低                    最多只丢失一个命令的数据。

      4.AOF 文件的读取和数据还原:
        a.创建一个不带网络连接的伪客户端（fake client）。
        b.读取 AOF 所保存的文本，并根据内容还原出命令、命令的参数以及命令的个数。
        c.根据命令、命令的参数和命令的个数，使用伪客户端执行该命令。
        d.执行 2 和 3 ，直到 AOF 文件中的所有命令执行完毕。
        # 因为 Redis 的命令只能在客户端的上下文中被执行，而 AOF 还原时所使用的命令来自于 AOF 文件，而不是网络，所以程序使用了一个没有网络连接的
        # 伪客户端来执行命令。伪客户端执行命令的效果，和带网络连接的客户端执行命令的效果，完全一样。

        # 为了避免对数据的完整性产生影响， 在服务器载入数据的过程中， 只有和数据库无关的订阅与发布功能可以正常使用， 其他命令一律返回错误。

      5.AOF 重写:
        被频繁操作的键，对它们所调用的命令可能有成百上千、甚至上万条，重写只是保留对某一个key的最终值，而不保留过程命令，类似多个命令的合并。

      # 由于性能问题，最好不要在master节点上做，而是在某一个slave上开启
      # http://redisbook.readthedocs.io/en/latest/internal/aof.html

10: 命令: #在线命令测试: http://try.redis.io/
  expire: 如果对key使用set或del命令，那么也会移除expire time，尤其是set命令。 # https://blog.csdn.net/westsource/article/details/6640526
  Incr: 将key中储存的数字值增一，如果key不存在，那么key的值会先被初始化为0，然后再执行INCR操作，且将key的有效时间设置为长期有效。
  setnx: 将key的值设为value，当且仅当key不存在。若给定的key已经存在，则SETNX不做任何动作。设置成功，返回1。设置失败，返回0。可用来实现分布式锁。如下：
          method(value -> 
            long result = redisClient.setnx(key, value);
            if(result == 1){
                redisClient.expire(key, seconds);
            } else if(redisClient.ttl(key)<0){
                redisClient.expire(key, secondes);
            }
            return result == 1;
          )
  启动: 
    后台启动：./src/redis-server ./redis.conf  #redis.conf中的daemonize yes
    前台启动：./src/redis-server
  
  进入客户端:
    ./src/redis-cli
  
  查看reids信息:
    info
  
  查看reids的client信息:
    client list

11: 修改查询逻辑：MOVED 重定向: #http://www.redis.cn/topics/cluster-spec.html
  一个 Redis 客户端可以自由地向集群中的任意节点（包括从节点）发送查询。接收的节点会分析查询，如果这个命令是集群可以执行的（就是查询中只涉及一个键），那么节点会找这个键
  所属的哈希槽对应的节点。如果刚好这个节点就是对应这个哈希槽，那么这个查询就直接被节点处理掉。否则这个节点会查看它内部的 哈希槽 -> 节点ID 映射，然后给客户端返回一个 
  MOVED 错误。一个 MOVED 错误如下：
  GET x
  -MOVED 3999 127.0.0.1:6381
  这个错误包括键（3999）的哈希槽和能处理这个查询的节点的 ip：端口号（127.0.0.1:6381）。客户端需要重新发送查询到给定 ip 地址和端口号的节点。 注意，即使客户端在重发查
  询之前等待了很长一段时间，与此同时集群的配置信息发生改变，如果哈希槽 3999 现在是为其他节点服务，那么目标节点会再向客户端回复一个 MOVED 错误。从集群的角度看，节点是以 
  ID 来标识的。我们尝试简化接口，所以只向客户端暴露哈希槽和用“ip:端口号”标识的 Redis 节点之间的映射。虽然并没有要求，但是客户端应该尝试记住哈希槽 3999 是服务于 
  127.0.0.1:6381。这样的话一旦有一个新的命令需要发送，它能计算出目标键的哈希槽，提高找到正确节点的机率。注意，当集群是稳定的时候，所有客户端最终都会得到一份哈希槽 -> 
  节点的映射表，这样能使得集群效率非常高：客户端直接定位目标节点，不用重定向、或代理或发生其他单点故障（single point of failure entities）。一个客户端也应该能处理本
  文后面将提到的 -ASK 重定向错误。
  ASK 和 MOVED的区别：我们简短地提到了 ASK 重定向（ASK redirection），为什么我们不能单纯地使用 MOVED 重定向呢？因为当我们使用 MOVED 的时候，意味着我们认为哈希槽永
  久地被另一个不同的节点处理，并且希望接下来的所有查询都尝试发到这个指定的节点上去。而 ASK 意味着我们只要下一个查询发送到指定节点上去。
  
12: Redis集群内部通讯协议：gossip 协议:
  Gossip 的特点：在一个有界网络中，每个节点都随机地与其他节点通信，经过一番杂乱无章的通信，最终所有节点的状态都会达成一致。每个节点可能知道所有其他节点，也可能仅知道几个
  邻居节点，只要这些节可以通过网络连通，最终他们的状态都是一致的，当然这也是疫情传播的特点。所以新节点接入的时候只要被一个节点识别，整个集群即发现了这个节点。所以和paxos
  相比，gossip会在传输中占用较多的网络流量。paxos是强一致性，而gossip是最终一致性。

13: Redis灵魂三问: 
  1.雪崩
    大促一般都是批量大数据load到缓存中，然后通过定时任务批量更新。如果某一时间所有缓存都时效，所有流量全部打到DB上，可能造成数据库崩溃。一般都过在缓存时间上加一个随机数
    来解决。
  2.穿透
    用一个数据库中不存在的值，比如id=-1请求查询，缓存和数据库中都不存在，这时的用户很可能是攻击者，攻击会导致数据库压力过大，严重会击垮数据库。通过参数校验解决。
  3.击穿
    击穿是指一个Key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个Key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个完好无损的桶上凿
    开了一个洞。
  总结：
    一般可以在Nginx做一个IP的限制，如WAF。还有Redis还有一个高级用法布隆过滤器（Bloom Filter）这个也能很好的防止缓存穿透的发生，他的原理也很简单就是利用高效的数据结构
    和算法快速判断出你这个Key是否在数据库中存在，不存在你return就好了，存在你就去查了DB刷新KV再return。
    # Redis一般面试题：https://juejin.im/post/5db66ed9e51d452a2f15d833














