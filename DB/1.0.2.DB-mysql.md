衡量标准：TPS（每秒事务量，一般几百、好的上千）


1: 登陆查询操作
2: 索引（常见问题优化）
3: 索引漫谈
4: 慢查询日志
5: 执行计划
6: 多表更新/主键
7: Mysql 5.7复制功能（mysql复制集群）
8: 秒杀案例
9: 锁




Mariadb:
cd /usr/local/opt/mariadb/bin
./mysql.server start

1: 登陆查询操作
    登陆数据库:
      mysql -h127.0.0.1 -uroot -p123456 --port=3306;
      mysql -h172.24.0.11 -um_jingcca -pBw6u7q --port=3306;

    查询数据库信息:
      status;

    列出当前Schema中所有的database:
      show databases; #select database();

    使用某一个数据库: 
      use database_name;

    列出数据库中所有的table:
      所有表: show tables [FROM db_name];
      查看表结构: desc table_name;   show create table table_name;
      查看表状态: show table status like 'table_name';
      查看字段: select column_name,column_comment from information_schema.columns where table_name = 'table_name';
      
      select * from book \G; #以列的形式显示结果集；

    查看和日志有关的变量:
    show variables like '%log%';


2: 索引
    索引／查询优化器的原理: http://www.ituring.com.cn/article/986
    索引查询快的原因：
        - 索引本身占用的磁盘空间比原来的表更少，导致扫描磁盘的块数少
        - 索引是有序的数据结构，查询算法（二分法）可以提高查询速度
    优化建议:
      * 一般在where、group by、order by、on从句中出现的列上加索引
      * 索引字段越小越好
      * 离散度高的字段放在联合索引的前面。#离散度：唯一值的个数（count唯一值大的）
        # 查询优化器会在离散度小于记录数的30%时放弃索引，实际上等于索引纯粹只会浪费空间。
      * 同一个字段「尽量」不要重复、冗余建立索引
      * 根据离散度、选择度优化，根据选择度优化步骤：
        选择度优化步骤:
          - show index from table_name   确定第三步使用哪一个索引（优先唯一索引）
          - show table status like table_name   确定第三步limit使用的数量
          - select count(*) from (select cl1 from table_name FORCE INDEX(uniq_id) order by cl2 desc limit 10000) table_name where cl1 = '123123'
            查询出来的值除以limit的值就是选择度，选择度最大1，越大越好。

    分析sql：（information_schema下执行）
    select
      a.TABLE_SCHEMA AS '数据名',
      a.TABLE_NAME AS '表名',
      a.INDEX_NAME AS '索引1',
      b.INDEX_NAME AS '索引2',
      a.COLUMN_NAME as '重复列名'
    from STATISTICS a JOIN STATISTICS b ON
      a.TABLE_SCHEMA = b.TABLE_SCHEMA
      AND a.TABLE_NAME = b.TABLE_NAME
      AND a.SEQ_IN_INDEX = b.SEQ_IN_INDEX
      AND a.COLUMN_NAME = b.COLUMN_NAME

    查看索引: show index from table_name; 
    分析工具: pt-duplicate-key-checker 
    未使用索引: MariaDB：INDEX_STATISTICS表可以分析，Mysql只能通过工具
    冗余索引: 用固定的SQL分析查找。或者pt-duplicate-key-checker工具，可给出修改建议。
    不用的索引: 慢查询+pt-index-usage工具，主从结构时要分析所有DB。

    常见问题优化:
      Max(name): 使用name索引，全覆盖索引，执行时间永远恒定
      子查询 Vs 链接查询: 有时需要用链接查询替换子查询，以规避临时表、文件排序；有时需要用子查询 + Group by替换链接查询，以规避临时表。
      limit: 常伴随order by操作，会增加大量的 I/O 操作。
             优化: 1.limit之前用主键或者索引列order by一下。  2.记录上次所描的列数，作为下次的where条件，以减少每次扫描的行数。

3: 索引漫谈
   Q：为什么选择B+而不是哈希表、二叉树或者BTree:
   A：Mysql选用B+树这种数据结构作为索引，可以提高查询索引时的磁盘IO效率( 一个节点默认一页，Mysql的Innodb引擎中一页的默认大小是16k（如果操作系统中一页大小是4k，那
      么Mysql中1页=操作系统中4页） )，并且可以提高范围查询的效率(原因在于B+树中的非叶子节点会冗余一份在叶子节点中，并且叶子节点之间用指针相连。另，哈希表不支持范围
      查找)，并且B+树里的元素也是有序的。

       PS：为什么有人平时说B+非叶子节点不存数据:
       通常我们认为B+树的非叶子节点不存储数据，只有叶子节点才存储数据；而B树的非叶子和叶子节点都会存储数据，会导致非叶子节点存储的索引值会更少，树的高度相对会比B+树
       高，平均的I/O效率会比较低，所以使用B+树作为索引的数据结构，再加上B+树的叶子节点之间会有指针相连，也方便进行范围查找。

    Q：主键索引vs辅助索引:
    A：InnoDB中主键索引的叶子节点的数据区域存储的是数据记录，辅助索引存储的是主键值。Innodb中的主键索引和实际数据时绑定在一起的，也就是说Innodb的一个表一定要有主键
       索引，如果一个表没有手动建立主键索引，Innodb会查看有没有唯一索引，如果有则选用唯一索引作为主键索引，如果连唯一索引也没有，则会默认建立一个隐藏的主键索引（用户
       不可见）。另外，Innodb的主键索引要比MyISAM的主键索引查询效率要高（少一次磁盘IO），并且比辅助索引也要高很多。所以，我们在使用Innodb作为存储引擎时，我们最好：
       a.手动建立主键索引
       b.尽量利用主键索引查询

    Q：为什么一个节点1页(16k)就可以了:
    A：假设我们一行数据大小为1K，那么一页就能存16条数据，也就是一个叶子节点能存16条数据；再看非叶子节点，假设主键ID为bigint类型，那么长度为8B，指针大小在Innodb源
       码中为6B，一共就是14B，那么一页里就可以存储16K/14=1170个(主键+指针)，那么一颗高度为2的B+树能存储的数据为：117016=18720条，一颗高度为3的B+树能存储的数据
       为：11701170*16=21902400（千万级条）。所以在InnoDB中B+树高度一般为1-3层，它就能满足千万级的数据存储。在查找数据时一次页的查找代表一次IO，所以通过主键索
       引查询通常只需要1-3次IO操作即可查找到数据。所以也就回答了我们的问题，1页=16k这么设置是比较合适的，是适用大多数的企业的，当然这个值是可以修改的，所以也能根据
       业务的时间情况进行调整。

    Q：为什么索引字段不建议太长:
    A：（1）MyISAM的索引与数据分开存储，索引叶子存储指针，主键索引与普通索引无太大区别；
       （2）InnoDB的聚集索引和数据行统一存储，聚集索引存储数据行本身，普通索引存储主键；
       （3）InnoDB不建议使用太长字段作为PK（此时可以加入一个自增键PK）浪费内存和缓存空间，MyISAM则无所谓；
    PS：MyISAM的索引与记录存储分离，有单独的区域存储行记录，PK是非聚集索引。

    Q：为什么在并发插入量比较大的时候，比较适合使用MyISAM呢？不会因为表锁频繁冲突而导致吞吐量降低吗:
    A：MyISAM的索引与记录存储分离，有单独的区域存储行记录，PK是非聚集索引。MyISAM表，如果数据文件(data file)紧密存储，中间没有空闲块(free blocks)，数据总是插入
       到数据文件的尾部(end)，就如同追加日志一样，性能很高，此时的并发insert与select是不加锁的(lock free)。MyISAM表，如果数据文件(data file)中间有空洞(hole)
       （删除产生的），上述机制会失效，直到空洞被新数据填满，又会启用不加锁机制。
 

4: 慢查询日志
    记录的是整个数据库服务器的信息，而不是单个的schema信息

    查看mysql是否开启慢查询日志: show variables like 'slow_query_log';

    开启慢查询日志: set global slow_query_log=on;
    查看日志存储路径: show variables like 'slow_query_log_file';
    设置日志存储路径: set global show_query_log_file=‘/home/mysql/sql_log/mysql-slow.log’ #该目录是exit数据库后宿主机的位置

    记录【没有使用索引】的查询sql到慢查询日志: set global log_queries_not_using_indexes=on;

    记录查询超过多少秒的sql到日志中: show variables like 'long_query_time';
    设置时间: set global long_query_time=1; # 一般1秒很大，正常是100ms

    日志中记录的每一条记录信息格式如下: 
                                - # Time: 170716 13:51:27
                                - # User@Host: root[root] @ localhost []
                                - # Thread_id: 13  Schema: work-product  QC_hit: No
                                - # Query_time: 0.000208  Lock_time: 0.000044  Rows_sent: 48  Rows_examined: 48
                                - # Rows_affected: 0
                                - SET timestamp=1500184287;
                                - select * from shb_classes;

    #以上设置需要退出、进入后才能show到更新后的值；   

    慢查询工具: 
            - mysqldumpslow:
              不需要安装，mysql自带的；但是功能较少
                command: mysqldumpslow -t 4 /tmp/mysql-slow.log
                         mysqldumpslow -t 4 /tmp/mysql-slow.log | more # 通过more工具查看

            - pt-query-digest: 
              分析慢查询日志文件比mysqldumpslow更丰富 #http://blog.csdn.net/seteor/article/details/24017913
                输出到文件: pt-query-digest show-log > slow_log.report
                输出到数据库表: pt-query-digest show.log -review \
                h=127.0.0.1,D=test,p=root.P=3306,u=root,t=query_review \
                --create-reviewtable \
                --review-history t=hostname_show

                pt-query-digest分析慢查询日志文件比mysqldumpslow更丰富: 
                    1.显示日志的时间范围,以及总的sql数量.
                    2.表的统计信息sql响应时间和执行次数。
                    3.具体的sql
                解决: 
                    1.查询时间长,查询次数多
                    2.IO大的sql,分析Rows Examine项,扫描的行数
                    3.未命中索引的sql,分析Rows Examine与Rows send发送的行数的对比

            - pt-query-digest安装: #http://blog.csdn.net/wireless_com/article/details/51615627
              1.http://www.percona.com/downloads/percona-toolkit
              2.tar xvfz percona-toolkit-2.2.7.tar.gz
              3.cd percona-toolkit-2.2.17
              4.perl Makefile.PL
              5.sudo perl -MCPAN -e "install DBI"
              6.sudo perl -MCPAN -e "install DBD::mysql" #`ld: library not found for -lssl` -> The solution was:xcode-select --install
              7.perl Makefile.PL --mysql_config=/usr/local/opt/mariadb/bin/mysql_config
              8.make
              9.make install


5: 执行计划
    MariaDB [dalin]> explain select * from book;
    # +------+-------------+-------+------+---------------+------+---------+------+------+-------+
    # | id   | select_type | table | type | possible_keys | key  | key_len | ref  | rows | Extra |
    # +------+-------------+-------+------+---------------+------+---------+------+------+-------+
    # |    1 | SIMPLE      | book  | ALL  | NULL          | NULL | NULL    | NULL |    4 |       |
    # +------+-------------+-------+------+---------------+------+---------+------+------+-------+

    table: 显示这一行的数据是关于哪张表的
    type: 这是重要的列,显示连接使用了何种类型。从最好到最差的连接类型为const、eq_reg、ref、range、index和ALL
    possible_keys: 显示可能应用在这张表中的索引。如果为空，没有可能的索引。
    key: 实际使用的索引。如果为NULL，则没有使用索引。
    key_len: 使用的索引的长度。在不损失精确性的情况下，长度越短越好。
    ref: 显示索引的哪一列被使用了,如果可能的话，是一个常数
    rows: MYSQL认为必须检查的用来返回请求数据的行数
    extra列需要注意的返回值: 
      Using filesort: 看到这个的时候，查询就需要优化了。MYSQL需要进行额外的步骤来发现如何对返回的行排序。它根据连接类型以及存储排序键值和匹配条件的全部行的行指针来排序全部行
      Using temporary: 看到这个的时候，查询需要优化了。这里，MYSQL要创建一个临时表来存储接口，这通常发生在对不同的列表进行ORDER BY上，而不是GROUP BY上。
      # 注意: 尽量不要使用临时表、文件排序。
      filesort一般是有orderby引起的，对于datetime类型的需要和where条件中的一个一起加一个联合索引。
      优化前： 
        ![image](img/BeforeAddIndex.jpeg)
      优化后： 
        ![image](img/AfterAddIndex.jpeg)

    优化:  # 衡量标准：TPS（每秒事务量，一般几百、好的上千）  JingKa的最差的0.31s扫描38万数据
         --------------优化-表扫描/索引扫描-------------
         -I/O：最根本的优化，RowsSent-RowsExamine的差

         慢查询: pt_query_disgest工具
         -table: 是否使用了表扫描
         -rows: 扫描的行数
         -extra: using filesort/temporary文件/临时表 数据转储
         -type: const、eq_reg、ref、range、All（最慢）
         -count()优化: *和具体字段不一样，区别在于null的
         -Max()优化: 不查表、只查index的sql-覆盖索引
         -子查询优化: 转化成join的时可能会1对多,用distinct
         -groupby优化: 子查询缩小范围，同时把聚合函数放子查询里；尽量！可以减少临时表等方式。
         limit优化: 主要思想是避免过多行数的扫描。1.主键排序可以减少I/O操作；2.记录上次扫描到的id，从这个id开始可以固定扫描行数（缺点：逐渐一定要顺序增长和连续，如果不是可见建立辅助列）。
     
         -------------------设计优化-------------------
         范式化（第三范式化）
         反范式化（字段冗余）
         垂直拆分
         水平拆分
         字段: int优于time优于varchar优于text
         索引: 散列值/离散度高（count唯一值大的）、小字段、不要字段冗余；离散度高的放在联合索引前面。过多的index不仅影响写，还增加查时的分析时间--删除重复和多余的index。
         选择度: 索引的可选择度指的是索引列包含的唯一值数量与索引列所有数据行数的比例(T),一个高选择度的列索引会使MySQL在检索时过滤掉更多的数据,最好的一种情况是唯一索引,它的可选择度为1
                select count(*) from (select cl1 from table_name FORCE INDEX(uniq_id) order by cl2 desc limit 10000) table_name where cl1 = '123123';
         冗余索引: 用固定的SQL分析查找。或者pt-duplicate-key-checker工具，可给出修改建议。
         不用的索引: 慢查询+pt-index-usage工具，主从结构时要分析所有DB。

    主从同步:  
         ![image](img/mysqlBinLog-sync.png)



6: 多表更新/主键
    update table1 INNER_JOIN table2 on t1.cln = t2.cln set t1.cln_1 = t2.cln_2; #参考table2更新table1

    ALTER TABLE author DROP PRIMARY KEY;
    ALTER TABLE author modify id int(11) NOT NULL AUTO_INCREMENT PRIMARY KEY;


7: Mysql 5.7复制功能（mysql复制集群）
    Mysql复制: 异步（默认方式，半同步也是异步也有延迟）（受主的写的频率影响：主的写是并发的，而log操作同步到salve是单线程的）
    
    Mysql的复制是基于BinLog的:
      三种日志格式: 
        Statement: 存储SQL语句，文件小，某些函数可能会造成主从不一致，不建议使用
        Row: 存储event数据，存储日志量大，但是不能很直接的进行读取
        Mixed: 介于Row和Statement之间，对于不确定的操作使用Row记录，如果每天数据操作量很大，产生的日志比较多，可以考虑选择mixed格式。
    
    部分复制: mysql的复制可以是整个数据库实例或者是某个库，某个表.
            主要通过master的binlog-do-db哪些要记录日志  -ignore-db哪些不用记录日志，slave可以通过replicate -do-db. 
            -ignore-db...等复制命令进行同步进行控制.建议一般是通过slave端进行控制，可以更精细化的控制,master建立完整的日志操作。

    复制类型: 
        二进制日志的复制、
        5.5之前是基于二进制的日志类型复制，但主从切换时无法确定具体的切换点。使用gtid基于全局事务的复制，每一个事务对应一个全局标识，可
        以很容易的找到复制点。为高可用带来很大方便。mysql5.7开始支持半同步优化主从复制，通过安装一些插件，日志先入的方式，等待某一个或者
        某几个slave返回确认ok后进行真正的事务提交。


8: 秒杀案例: #http://www.cnblogs.com/clphp/p/6398667.html
  Step1:
    1.接下来，每次插入前执行以下以下操作检查一下是否超卖即可：
      select sum(buy_count) from UserProduct where product_id = ?
    2.最后还要检查一下这个用户是否购买过：
      select count(*) from UserProduct where user_id = ? and product_id = ?
    3.全都没问题了就插入数据：
      insert into UserProduct (user_id, product_id, buy_count) values (?, ?, ?)

  Step2-优化:
    3的问题-保证单用户不会重复购买：加上唯一索引(user_id, product_id)

  Step3-优化: （一般秒杀场景够用）
    1、2的问题-解决超卖问题：1的SQL加上for update，三个语句放在同一个事物中 
    # 为了for update是行锁而不是表锁，需要在product_id上加一个索引

  Step4-优化: （超大规模秒杀场景够用）
    Step3的优化会影响性能。
    对策：去掉事物，同时把1的语句换成如下：
    update Product set buy_count = buy_count+? where id = ? and buy_count+? <= buy_max
    
  最终方案:
    1.update Product set buy_count = buy_count+? where id = ? and buy_count+? <= buy_max
    2.insert into UserProduct (user_id, product_id, buy_count) values (?, ?, ?) #有唯一索引
    同时，如果第二步失败了（重复购买），需要逆向执行一句1的SQL，把库存还回去。

9: 锁
    通常情况下，下列四种情况，表锁会优于行锁：
    * 该表的大多数语句均为读
    * 该表的语句是读和写的混合，其中写是对单行的更新或删除，可通过一次按键读取来获取：
        UPDATE tbl_name SET column=value WHERE unique_key_col=key_value;
        DELETE FROM tbl_name WHERE unique_key_col=key_value;
    * SELECT与并发INSERT语句结合使用，很少有 UPDATE or DELETE语句
    * 在整個表中执行很多扫描或GROUP BY操作时沒有任何写。
    PS：如果业务经常读写表中很大一部分数据时，表锁会更快，因为此时只涉及一个锁，而不是同时管理N多个锁；
















