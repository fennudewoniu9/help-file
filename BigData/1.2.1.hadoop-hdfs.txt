中文官方文档: https://hadoop.apache.org/docs/r1.0.4/cn/cluster_setup.html
■ 硬件故障:
硬件故障是规范而不是例外。一个HDFS实例可以由数百或数千个服务器机器组成，每个服务器机器存储部分文件系统的数据。事实上，
有大量的组件，每个组件都有一个不平凡的失败概率，这意味着HDFS的某个组件总是不起作用的。因此，检测故障和快速自动恢复是
HDFS的核心架构目标。

■ “移动计算比移动数据更划算”:
一个应用请求的计算，离它操作的数据越近就越高效，在数据达到海量级别的时候更是如此。因为这样就能降低网络阻塞的影响，提高系统
数据的吞吐量。将计算移动到数据附近，比之将数据移动到应用所在显然更好。HDFS为应用提供了将它们自己移动到数据附近的接口。

■ RPC框架:
http://ifeve.com/hortonworkshdp-hdpcd/(Hortonworks(HDP)开发者认证)
■====================================================================
■JDK中已经自带了一个RPC框架——RMI（远程方法调用），之所以不直接使用该框架，主要是考虑到RPC是Hadoop最底层最核心的模块之一，          
■保证其轻量级、高性能和可控性显得尤为重要，而RMI是一个重量级框架且用户可控之处太少。（Doug Cutting就是这样描述Hadoop RPC设计动机的） 
■Hadoop使用的是Socket自己实现的一套rpc机制（org.apache.hadoop.ipc.RPC）                                                         
■====================================================================

■ 通讯协议:
所有的HDFS通讯协议都是建立在TCP/IP协议之上。客户端通过一个可配置的TCP端口连接到Namenode，通过ClientProtocol协议与Namenode交互。而
Datanode使用DatanodeProtocol协议与Namenode交互。一个远程过程调用(RPC)模型被抽象出来封装ClientProtocol和Datanodeprotocol协议。在
设计上，Namenode不会主动发起RPC，而是响应来自客户端或 Datanode 的RPC请求。

■ 文件系统元数据的持久化（checkpoint）: 
Namenode上保存着HDFS的名字空间。对于任何对文件系统元数据产生修改的操作，Namenode都会使用一种称为EditLog的事务日志记录下来。例如，在HDFS中创建一个文件，Namenode
就会在Editlog中插入一条记录来表示；同样地，修改文件的副本系数也将往Editlog插入一条记录。Namenode在本地操作系统的文件系统中存储这个Editlog。整个文
件存储系统的命名空间，包括数据块到文件的映射、文件的属性等，都存储在一个称为FsImage的文件中，这个文件也是放在Namenode所在的本地文件系统上。
1.当Namenode启动时，它从硬盘中读取Editlog(操作日志)和FsImage（整个文件系统的名字空间），将所有Editlog中的事务作用在内存中的FsImage上，并将这个新版本
  的FsImage从内存中保存到本地磁盘上，然后删除旧的Editlog，因为这个旧的Editlog的事务都已经作用在FsImage上了。这个过程称为一个检查点(checkpoint)。
2.当一个Datanode启动时，它会扫描本地文件系统，产生一个这些本地文件对应的所有HDFS数据块的列表，然后作为报告发送到Namenode，这个报告就是块状态报告(Blockreport)。

因为NameNode只有在启动阶段才合并fsimage和edits，所以久而久之日志文件可能会变得非常庞大，特别是对大型的集群。日志文件太大的另一个副作用是下一次NameNode启动
会花很长时间。所以启动后正常运行的时候两个文件的合并是由Secondary NameNode控制的。
■====================================================================
■Secondary NameNode定期执行合并Editlog和FsImage，Secondary NameNode的检查点进程启动，是由两个配置参数控制的：
■fs.checkpoint.period，指定连续两次检查点的最大时间间隔， 默认值是1小时。
■fs.checkpoint.size定义了edits日志文件的最大值，一旦超过这个值会导致强制执行检查点（即使没到检查点的最大时间间隔）。默认值是64MB。
■====================================================================

■ 数据复制:
Namenode全权管理数据块的复制，它周期性地从集群中的每个Datanode接收心跳信号和块状态报告(Blockreport)。接收到心跳信号意味着该Datanode节点工
作正常。块状态报告包含了一个该Datanode上所有数据块的列表。

■ 安全模式:
处于安全模式的Namenode是不会进行数据块的复制的。每个数据块都有一个指定的最小副本数。当Namenode检测确认某个数据块的副本数目小于这个最小值，Namenode不断地检测这些需
要复制的数据块，一旦发现就启动复制操作。

■ 磁盘数据错误，心跳检测和重新复制:
Namenode将这些近期不再发送心跳信号Datanode标记为宕机，不会再将新的IO请求发给它们。任何存储在宕机Datanode上的数据将不再有效。Namenode不断地检测这些需
要复制的数据块，一旦发现就启动复制操作。在下列情况下，可能需要重新复制：某个Datanode节点失效，某个副本遭到损坏，Datanode上的硬盘错误，或者文件的副本系数增大。

■fsck:
HDFS支持fsck命令来检查系统中的各种不一致状况。这个命令被设计来报告各种文件存在的问题，比如文件缺少数据块或者副本数目不够。NameNode会自动修正大多数可恢复的错
误，所以该fsck不同于在本地文件系统上传统的fsck工具，这个命令并不会修正它检测到的错误。


■ 存储空间回收:
1.文件的删除和恢复
当用户或应用程序删除某个文件时，这个文件并没有立刻从HDFS中删除。实际上，HDFS会将这个文件重命名转移到/trash目录。只要文件还在/trash目录中，该文件就可以被迅速地恢复。
目前的默认策略是删除/trash中保留时间超过6小时的文件。将来，这个策略可以通过一个被良好定义的接口配置。
注意，从用户删除文件到HDFS空闲空间的增加之间会有一定时间的延迟。

2.减少副本系数
当一个文件的副本系数被减小后，Namenode会选择过剩的副本删除。下次心跳检测时会将该信息传递给Datanode。Datanode遂即移除相应的数据块，集群中的空闲空间加大。
同样，在调用setReplication API结束和集群中空闲空间增加间会有一定的延迟。

■ 权限管理:
每次文件或目录操作都传递完整的路径名给name node，每一个操作都会对此路径做权限检查。重复一下，权限的改变并不会撤销当前客户端对文件数据块的访问许可；因为第一次请求的时
候客户端已经获得了对文件相关的所有数据块的访问权限。而权限管理能使得客户端对一个文件的访问许可在两次请求之间被收回。

■【YARN：新的 Hadoop MapReduce 框架命名为 MapReduceV2 或者叫 Yarn】:
http://www.csdn.net/article/2014-02-10/2818355
https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-yarn/（老 Hadoop 的 Map-Reduce 只能支持 4000 节点主机的上限。）（新旧 Hadoop 框架）
http://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/（Hadoop NameNode 高可用 (High Availability) 实现解析）
重构根本的思想是将 JobTracker 两个主要的功能分离成单独的组件，这两个功能是资源管理和任务调度 / 监控。

【ResourceManager】：作为资源的协调者有两个主要的组件：Scheduler和ApplicationsManager(AsM)。负责作业与资源的调度。接收 JobSubmitter 提交的作业，按照作业的上
    下文 (Context) 信息，以及从 NodeManager 收集来的状态信息，启动调度过程，然后分配一个Container 作为 App Mstr，同时监控 ApplicationMaster的存在情况（由RM
    中的一个模块ApplicationsMasters负责）。从某种意义上讲它就是一个纯粹的调度器，在执行过程中不对应用进行监控和状态跟踪。也不能重启因应用失败或者硬件错误而运行失败的
    任务（有ApplicationMaster负责）。

【NodeManager】：每一台机器框架的代理，是执行应用程序的容器，监控应用程序的资源使用情况 (CPU，内存，硬盘，网络 ) 并且向调度器（ResourceManager）汇报。同时负
    责 Container 状态的维护，并向 RM 保持心跳。

【ApplicationMaster】：向调度器（ResourceManager）索要适当的资源容器，运行任务，跟踪应用程序的状态和监控它们的进程，处理任务的失败原因。 负责一个 Job 生命周期内的
    所有工作，类似老的框架中 JobTracker。但注意每一个 Job（不是每一种）都有一个 ApplicationMaster，它可以运行在 ResourceManager 以外的机器上。

【Container】：是 Yarn 为了将来作资源隔离而提出的一个框架。目前是一个框架，仅仅提供 java 虚拟机内存的隔离 ,hadoop 团队的设计思路应该后续能支持更多的资源调度和控制,
    既然资源表示成内存量，那就没有了之前的 map slot/reduce slot 分开造成集群资源闲置的尴尬情况。


■Yarn（MapReduceV2）与MP的主要资源衡量标准:
老MP以剩余slot数目
Yarn以内存为单位( 在目前版本的 Yarn 中，没有考虑 cpu 的占用)












