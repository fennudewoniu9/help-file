0.0: 序
    Nginx使用多进程的方法进行任务处理，每个worker进程只有一个线程，单线程循环处理全部监听的事件。
    nginx的内部结构是由核心部分和一系列的功能模块所组成。这样划分是为了使得每个模块的功能相对简单，便于开发，同时也便于对系统进行功能扩展。
        * 获取客户端的真实IP模块: read_ip模块 # 需要安装，安装后重新加载即可
        * 限流、白名单: https://www.cnblogs.com/peteremperor/p/7342143.html
            - 需要用到ngx_http_limit_req_module，ngx_stream_limit_conn_module模块 
              # 基于令牌桶算法，可以方便的控制令牌速率，自定义调节限流，实现基本的限流控制。
              # 对于提供下载的网站，肯定是要进行流量控制的，例如软件下载站、视频服务等。它也可以减少一些爬虫程序或者DDOS的攻击。
            - 需要用到Ngx自带的map和geo模块
        * 限制ip并发数: http://hopestar.github.io/2013/06/08/nginx-limit-moule-note/

0.1: nginx配置详解 # http://tengine.taobao.org/book/chapter_02.html
    以下是一个完整的nginx.conf内容:  # 备注：有些变量只能在http里有效，有的只能在server里有效。events等也是如此。
    # For more information on configuration, see:
    #   * Official English Documentation: http://nginx.org/en/docs/
    #   * Official Russian Documentation: http://nginx.org/ru/docs/
    
    #[注释]: nginx在运行时与具体业务功能（比如http服务或者email服务代理）无关的一些参数，比如工作进程数，运行的身份等。
    user nginx;
    worker_processes auto;  #[注释]: 从master进程forker的worker数，一般和cpu核数保持一致
    error_log /var/log/nginx/error.log;
    pid /run/nginx.pid;

    # Load dynamic modules. See /usr/share/nginx/README.dynamic.
    include /usr/share/nginx/modules/*.conf;

    events {
        worker_connections 1024;  #[注释]: 每一个worker进程支持的最大连接数，如果大于操作系统的nofile会警告，且最终生效的是nofile
    }

    http {  #[注释]: 与提供http服务相关的一些配置参数。例如：是否使用keepalive啊，是否使用gzip进行压缩等。如果是邮件服务，需要换成mail。
        log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                          '$status $body_bytes_sent "$http_referer" '
                          '"$http_user_agent" "$http_x_forwarded_for"';

        access_log  /var/log/nginx/access.log  main;

        sendfile            on;  # 零拷贝，Linux2.0+以后4次拷贝变2次。http://xiaorui.cc/2015/06/24/扯淡nginx的sendfile零拷贝的概念/
        tcp_nopush          on;  # 定量发送；调用tcp_cork方法，数据包不马上传送出去，等到包最大时一次性传出，有助于解决网络堵塞。使用sendfile函数时才生效；和指令tcp_nodelay互斥（一个定时、一个定量）
        tcp_nodelay         on;  # 定时发送；禁用Nagle 算法（一种压缩算法，把一段时间内较小的包组装为更大的帧）；和指令tcp_nopush互斥（一个定时、一个定量）
        keepalive_timeout   65;  #[注释]: 长链接保持时间如果配置为0，则表示关掉keepalive，此时，http版本无论是1.1还是1.0，客户端的connection不管是close还是keepalive，都会强制为close。
        types_hash_max_size 2048;

        server_tokens off;       # 可以关闭在错误页面中的nginx版本数字

        include             /etc/nginx/mime.types;
        default_type        application/octet-stream;

        # Load modular configuration files from the /etc/nginx/conf.d directory.
        # See http://nginx.org/en/docs/ngx_core_module.html#include
        # for more information.
        include /etc/nginx/conf.d/*.conf;

        server {  #[注释]: http服务上支持若干虚拟主机。每个虚拟主机对应一个server配置项，配置项里面包含该虚拟主机相关的配置。在提供mail服务的代理时，也可以建立若干server.每个server通过监听的地址来区分。
            listen       80;
            server_name  www.fyqiushi.cn;   #server_name指令主要用于配置基于名称的虚拟主机，可以使用正则表达式
            root         /usr/share/nginx/html;

            # Load configuration files for the default server block.
            include /etc/nginx/default.d/*.conf;

            location / {  # http服务中，特定的URL对应的配置项。
                  proxy_pass http://localhost:81;
            }

            error_page 404 /404.html;
                location = /40x.html {
            }

            error_page 500 502 503 504 /50x.html;
                location = /50x.html {
            }
        }

        # Settings for a TLS enabled server.
        #
        #    server {
        #        listen       443 ssl http2 default_server;
        #        listen       [::]:443 ssl http2 default_server;
        #        server_name  _;
        #        root         /usr/share/nginx/html;
        #
        #        ssl_certificate "/etc/pki/nginx/server.crt";
        #        ssl_certificate_key "/etc/pki/nginx/private/server.key";
        #        ssl_session_cache shared:SSL:1m;
        #        ssl_session_timeout  10m;
        #        ssl_ciphers HIGH:!aNULL:!MD5;
        #        ssl_prefer_server_ciphers on;
        #
        #        # Load configuration files for the default server block.
        #        include /etc/nginx/default.d/*.conf;
        #
        #        location / {
        #        }
        #
        #        error_page 404 /404.html;
        #            location = /40x.html {
        #        }
        #
        #        error_page 500 502 503 504 /50x.html;
        #            location = /50x.html {
        #        }
        #    }

        # mail {
        #     auth_http  127.0.0.1:80/auth.php;
        #     pop3_capabilities  "TOP"  "USER";
        #     imap_capabilities  "IMAP4rev1"  "UIDPLUS";
        # 
        #     server {
        #         listen     110;
        #         protocol   pop3;
        #         proxy      on;
        #     }
        #     server {
        #         listen      25;
        #         protocol    smtp;
        #         proxy       on;
        #         smtp_auth   login plain;
        #         xclient     off;
        #     }
        # }

        }

1: yum方式安装代理
yum install tinyproxy
yum remove tinyproxy

/etc/tinyproxy/tinyproxy.conf

service tinyproxy start
service tinyproxy restart

MAC：10.199.75.12 8080

2: CentOS安装Nginx -- yum
    yum install nginx  # 安装
    yum remove nginx   # 删除
    
    service nginx start  # 启动
    或者
    cd nginx目录
    nginx -c /etc/local/nginx/nginx.conf
    
    注: 
      * 指定不同的配置文件可以启动不同的实例
      * 求实／红蝠两个结构：一台在前面域名负载，两台对应相应的实例
      * 在对应的nginx目录下执行以下命令，对应的nginx就会重新加载 nginx -s reload


3: CentOS安装Nginx -- 编译
    # http://www.nginx.cn/install
    以下所有操作都是在/usr/local/src进行的:
    yum -y install gcc automake autoconf libtool make
    yum install gcc gcc-c++

    wget http://ftp.pcre.org/pub/pcre/pcre-8.37.tar.gz
    tar -zxvf pcre-8.37.tar.gz
    cd pcre-8.34
    ./configure
    make
    make install

    wget http://prdownloads.sourceforge.net/libpng/zlib-1.2.8.tar.gz
    tar -zxvf zlib-1.2.8.tar.gz
    cd zlib-1.2.8
    ./configure
    make
    make install

    wget https://www.openssl.org/source/openssl-1.0.1t.tar.gz
    tar -zxvf openssl-1.0.1t.tar.gz

    wget http://nginx.org/download/nginx-1.4.2.tar.gz
    tar -zxvf nginx-1.4.2.tar.gz
    cd nginx-1.4.2
     
    ./configure --sbin-path=/usr/local/nginx/nginx \
    --conf-path=/usr/local/nginx/nginx.conf \
    --pid-path=/usr/local/nginx/nginx.pid \
    --with-http_ssl_module \
    --with-pcre=/opt/app/openet/oetal1/chenhe/pcre-8.37 \
    --with-zlib=/opt/app/openet/oetal1/chenhe/zlib-1.2.8 \
    --with-openssl=/opt/app/openet/oetal1/chenhe/openssl-1.0.1t
     
    make
    make install
    注: configure的参数需要参考实际安装的组件进行修改

  命令: 
    Nginx -s stop      # 快速关闭Nginx，可能不保存相关信息，并迅速终止web服务。                            
    Nginx -s quit      # 平稳关闭Nginx，保存相关信息，有安排的结束web服务。                          
    Nginx -s reload    # 启动一新的master,同时会向老master发送信号,老master启动新的worker,老worker不再接受请求,同时处理中的请求处理完成后再退出        
    Nginx -s reopen    # 重新打开日志文件。 
    nginx/bin/nginx -t # 查看


4: 多域名映射
    server {
        listen       80;
        server_name  www.fyqiushi.cn;
        root         /usr/share/nginx/html;

        # Load configuration files for the default server block.
        include /etc/nginx/default.d/*.conf;

        location / {
              proxy_pass http://localhost:81;
        }

        error_page 404 /404.html;
            location = /40x.html {
        }

        error_page 500 502 503 504 /50x.html;
            location = /50x.html {
        }
    }

    server {
        listen       80;
        server_name  www.hongfu-photo.com;
        root         /usr/share/nginx/html;

        # Load configuration files for the default server block.
        include /etc/nginx/default.d/*.conf;

        location / {
              proxy_pass http://localhost:82;
        }

        error_page 404 /404.html;
            location = /40x.html {
        }

        error_page 500 502 503 504 /50x.html;
            location = /50x.html {
        }
    }
    注: 修改后需要重新加载nginx.conf：nginx -s reload

    #server {
    #    listen       80 default_server;
    #    server_name  _name _;
    #    root         /usr/share/nginx/html;
    #    #return       444;
    #
    #    # Load configuration files for the default server block.
    #    include /etc/nginx/default.d/*.conf;
    #
    #    location / {
    #    }
    #
    #    error_page 404 /404.html;
    #        location = /40x.html {
    #    }
    #
    #    error_page 500 502 503 504 /50x.html;
    #        location = /50x.html {
    #    }
    }

5: 设置nginx只能通过域名访问 #https://www.cnblogs.com/fangbo/archive/2011/02/21/1959855.html
    设置一个默认的域名跳转到指定的页面即可，但是用户体验不好，可以不return而是rewrite。
    server {
        listen       80 default_server;
        server_name  _name _;
        return       404;

        # Load configuration files for the default server block.
        include /etc/nginx/default.d/*.conf;

        location / {
        }

        error_page 404 /404.html;
            location = /40x.html {
        }

        error_page 500 502 503 504 /50x.html;
            location = /50x.html {
        }
    }

6: nginx keepalive／长度／tcp时间 # http://tengine.taobao.org/book/chapter_02.html
  * 当nginx设置了keepalive等待下一次的请求时，同时也会设置一个最大等待时间，这个时间是通过选项keepalive_timeout来配置的
    ，如果配置为0，则表示关掉keepalive，此时，http版本无论是1.1还是1.0，客户端的connection不管是close还是keepalive，
    都会强制为close。
  * pipe在http1.1中引入的一种新的特性。pipeline其实就是流水线作业，它可以看作为keepalive的一种升华，因为pipeline也是基
    于长连接的，目的就是利用一个连接做多次请求。
    如果客户端要提交多个请求，对于keepalive来说，那么第二个请求，必须要等到第一个请求的响应接收完全后，才能发起，这和TCP的停
    止等待协议是一样的，得到两个响应的时间至少为2*RTT。而对pipeline来说，客户端不必等到第一个请求处理完后，就可以马上发起第
    二个请求。得到两个响应的时间可能能够达到1*RTT。nginx是直接支持pipeline的，但是，nginx对pipeline中的多个请求的处理却
    不是并行的，依然是一个请求接一个请求的处理，只是在处理第一个请求的时候，客户端就可以发起第二个请求。这样，nginx利用
    pipeline减少了处理完一个请求后，等待第二个请求的请求头数据的时间。
    原理: nginx在读取数据时，会将读取的数据放到一个buffer里面，所以，如果nginx在处理完前一个请求后，如果发现buffer里面还
    有数据，就认为剩下的数据是下一个请求的开始，然后就接下来处理下一个请求，否则就设置keepalive。
  * 延迟关闭。因为当出现错误码需要返回给客户端的时候，按照Nginx处理流程，所有数据会先写到writeBuffer里，所以,当在某些场景下
    出现tcp write buffer里的数据在write()系统调用之后到close()系统调用执行之前没有发送完毕，且tcp read buffer里面还有
    数据没有读，close()系统调用会导致客户端收到RST报文且不会拿到服务端发送过来的错误信息数据。那客户端肯定会想，这服务器好霸道
    ，动不动就reset我的连接，连个错误信息都没有。
    扩展: 调用close方法后的行为：内核会首先检查tcp的read buffer里有没有客户端发送过来的数据留在内核态没有被用户态进程读取，
    如果有则发送给客户端RST报文来关闭tcp连接丢弃write buffer里的数据，如果没有则等待write buffer里的数据发送完毕，然后再经
    过正常的4次分手报文断开连接。     为什么有数据就发送reset，因为客户端这时候不知道出错，可能还会继续发数据过来。
    全双工的延迟关闭: 先关闭写，过一会再关闭读；所以引入了一个读超时配置项。这个时间也就是nginx在关闭写之后，保留socket的时间
    ，客户端需要在这个时间内发送完所有的数据，否则nginx在这个时间过后，会直接关掉连接。当然，nginx是支持配置是否打开
    lingering_close选项的，通过lingering_close选项来配置。 那么，我们在实际应用中，是否应该打开lingering_close呢？这个
    就没有固定的推荐值了，如Maxim Dounin所说，lingering_close的主要作用是保持更好的客户端兼容性，但是却需要消耗更多的额外
    资源（比如连接会一直占着）。

7: nginx原理 # http://tengine.taobao.org/book/chapter_02.html
  * 默认是多进程的方式来工作，例如自己在阿里云上启动的三个nginx实例，阿里云上ps -ef|grep nginx结果如下：1个worker的原因：机器是单核的
    root     21167     1  0 Nov28 ?        00:00:00 nginx: master process nginx -c /etc/nginx_hf/nginx.conf
    nginx    21168 21167  0 Nov28 ?        00:00:00 nginx: worker process
    root     21171     1  0 Nov28 ?        00:00:00 nginx: master process nginx -c /etc/nginx/nginx.conf
    nginx    21172 21171  0 Nov28 ?        00:00:00 nginx: worker process
    root     21279     1  0 Nov28 ?        00:00:00 nginx: master process nginx -c /etc/nginx_qiushi/nginx.conf
    nginx    21280 21279  0 Nov28 ?        00:00:00 nginx: worker process
    root     22560 22540  0 10:06 pts/0    00:00:00 grep --color=auto nginx
    注: master和worker都必须kill掉后才可以重启nginx，且kill master后worker不回自动kill
    master进程主要用来管理worker进程，包含：接收来自外界的信号，向各worker进程发送信号，监控worker进程的运行状态，当worker
    进程退出后(异常情况下)，会自动重新启动新的worker进程。而基本的网络事件，则是放在worker进程中来处理了。多个worker进程之间是
    对等的，他们同等竞争来自客户端的请求，各进程互相之间是独立的。一个请求，只可能在一个worker进程中处理，一个worker进程，不可能
    处理其它进程的请求。worker进程的个数是可以设置的，一般我们会设置与机器cpu核数一致，这里面的原因与nginx的进程模型以及事件处理
    模型是分不开的。worker之间通过【互斥锁】相互协调。
  * 高并发: 
    每个worker里面只有一个主线程，nginx采用了异步非阻塞的方式来处理请求，也就是说，nginx是可以同时处理成千上万个请求的。apache的常用工作方
    式（apache也有异步非阻塞版本，但因其与自带某些模块冲突，所以不常用）。这也是为什么worker_processes auto;以及一个worker一个线程的原因，
    主要是为了充分利用CPU，更多的worker数，只会导致进程来竞争cpu资源了，从而带来不必要的上下文切换。而且，nginx为了更好的利用多核特性，提供
    了cpu亲缘性的绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来cache的失效。
  * 连接数（worker_connections）: 
    每个worker进程都有一个独立的连接池（数组），对应连接数的最大上限（每个socket连接会占用掉一个fd），当fd用完后，再创建socket
    时，就会失败且无法将此连接转交给其它进程，最终会导致此tcp连接得不到处理，就中止掉了。如果该值大于nofile（操作系统规定每个进程
    的最大连接数），那么实际的最大连接数是nofile，nginx会有警告。所以，一个nginx能建立的最大连接数，应该是
    worker_connections * worker_processes（HTTP请求本地资源时，如果作为反向代理：worker_connections * worker_processes/2，
    因为每个并发会建立与客户端的连接和与后端服务的连接，会占用两个连接）。
    ngx_accept_disabled变量--降低中止TCP连接概率的算法（竞争互斥锁的前置判断）：worker_connections／8 - 空余连接数，当小于
    0时候竞争互斥锁，当大于0时放弃竞争，同时ngx_accept_disabled - 1。这样，nginx就控制了多进程间连接的平衡了。

8: location解析规则
    # proxy_pass详解：http://ftlynx.blog.51cto.com/2833447/839607                                                                                                    
    下面四种情况分别用http://192.168.1.4/proxy/test.html 进行访问。                                                                                               
    第一种:                                                                                                
        location  /proxy/ {                                                                                         
                  proxy_pass http://127.0.0.1:81/;                                                                                          
        }                                                                                           
        # 会被代理到http://127.0.0.1:81/test.html 这个url                                                                                            
                                                        # 第一步：根据location把原url删除一样的部分      
    第二咱(相对于第一种，最后少一个 /):                      #       得到http://192.168.1.4和test.html
        location  /proxy/ {                             # 第二步：proxy_pass如果以／结尾，直接把上一步的第二部分跟在proxy_pass后面      
                  proxy_pass http://127.0.0.1:81;       #        proxy_pass如果不以／结尾，把location的部分放在第一步得到的两个部分中间                                                                    
        }                                                                                           
        # 会被代理到http://127.0.0.1:81/proxy/test.html 这个url                                                                                          
                                                                                                    
    第三种:                                                                                                
        location  /proxy/ {                                                                                         
                  proxy_pass http://127.0.0.1:81/ftlynx/;                                                                                           
        }                                                                                           
        # 会被代理到http://127.0.0.1:81/ftlynx/test.html 这个url                                                                                         
                                                                                                    
    第四种情况(相对于第三种，最后少一个 / ):                                                                                             
        location  /proxy/ {                                                                                         
                  proxy_pass http://127.0.0.1:81/ftlynx;                                                                                            
        }                                                                                           
        # 会被代理到http://127.0.0.1:81/ftlynxtest.html 这个url   

    取值: [=|~|~*|^~|/]
        = 开头表示精确匹配，后面不能带任何字符串
        ~ 开头表示区分大小写的正则匹配
        ~* 开头表示不区分大小写的正则匹配
        ^~ 开头表示uri以某个常规字符串开头。nginx不对url做编码，因此请求为/static/20%/aa，可以被规则^~ /static/ /aa匹配到（注意是空格）
        !~ 和 !~* 分别为区分大小写不匹配及不区分大小写不匹配的正则
        / 通用匹配，任何请求都会匹配到                                                                                       

9: 扩展
    ngx_stream_upstream_module: # used to define groups of servers that can be referenced by the proxy_pass directive.端口映射到群组。

    stream {
        resolver 10.0.0.1; # monitors changes of the IP addresses that correspond to a domain name of the server, and automatically
        # modifies the upstream configuration without the need of restarting nginx. The server group must reside in the shared memory.

        upstream backend1 {
        # upstream模块实现反向代理的功能，将真正的请求转发到后端服务器上，并从后端服务器上读取响应，发回客户端。upstream模块是一种特殊的handler，
        # 只不过响应内容不是真正由自己产生的，而是从后端服务器上读取的。
            hash $remote_addr consistent; # 不清楚，不知道是不是和sticky冲突。
            sticky; # 基于cookie的会话粘滞。ngx自带的ip_hash对于CDN和局域网用户，可能导致出现服务器分配不均衡，及不能保证每次访问都粘滞在同一台服务器。

            server backend1.example.com:12345  weight=5; # weight:路由轮训权重，7个连接中的前五个，后两个连接到后面的两个
            server backend2.example.com:12345;
            server unix:/tmp/backend3;

            server backup1.example.com:12345   backup; # marks the server as a backup server. Connections to the backup
            server backup2.example.com:12345   backup; # server will be passed when the primary servers are unavailable.
        }

        server {
            listen 12346;
            proxy_pass backend1;
        }
    }


10: 生产Nginx配置
    user  nginx;

    worker_processes 4;

    error_log  /app/data/logs/nginx/nginx_error.log  crit;
    pid        /var/run/nginx.pid;


    #Specifies the value for maximum file descriptors that can be opened by this process.
    worker_rlimit_nofile 51200;

    events {
        use epoll;
        worker_connections 50000;
        multi_accept on;
    }

    http {
        log_format  main  '$http_x_forwarded_for - $remote_user [$time_local] "$request" '
             '$status $body_bytes_sent "$http_referer" '
             '"$http_user_agent"  $request_time $remote_addr'  '[$upstream_status  $upstream_addr $upstream_response_time]';

        include       /etc/nginx/mime.types;
        default_type  application/octet-stream;

        server_names_hash_bucket_size 128;
        client_header_buffer_size 32k;
        large_client_header_buffers 4 32k;
        client_max_body_size 50m;

        sendfile   on;
        tcp_nopush on;

        keepalive_timeout 60;

        tcp_nodelay on;

        fastcgi_connect_timeout 300;
        fastcgi_send_timeout 300;
        fastcgi_read_timeout 300;
        fastcgi_buffer_size 64k;
        fastcgi_buffers 4 64k;
        fastcgi_busy_buffers_size 128k;
        fastcgi_temp_file_write_size 256k;

        gzip on;
        gzip_min_length  1k;
        gzip_buffers     4 16k;
        gzip_http_version 1.1;
        gzip_comp_level 2;
        gzip_types     text/plain application/javascript application/x-javascript text/javascript text/css application/xml application/xml+rss;
        gzip_vary on;
        gzip_proxied   expired no-cache no-store private auth;
        gzip_disable   "MSIE [1-6]\.";

        #limit_conn_zone $binary_remote_addr zone=perip:10m;
        ##If enable limit_conn_zone,add "limit_conn perip 10;" to server section.

        server_tokens off;
        access_log off;
        geo $http_x_forwarded_for $ip_blacklist {
        default 0;
        include ip_black.conf;
        }

        lua_package_path "/app/data/nginx/ngx_extend/thrid/?.lua;/app/data/nginx/ngx_extend/lua/?.lua;;";
        lua_package_cpath "/app/data/nginx/ngx_extend/thrid/lib/?.so;;";
        lua_shared_dict limit_req_store 100m;

        include /etc/nginx/conf.d/*.conf;
    }


