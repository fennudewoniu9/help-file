1: 下载 
	wget http://apache.fayea.com/kafka/0.10.2.0/kafka_2.11-0.10.2.0.tgz 
	     http://apache.fayea.com/kafka/0.10.2.1/kafka_2.10-0.10.2.1.tgz 
	     http://apache.fayea.com/zookeeper/zookeeper-3.3.6/zookeeper-3.3.6.tar.gz 


2: 复制到其他两台机器上/解压
	scp ./kafka_2.11-0.10.2.0.tgz hadoop@slave2:/home/hadoop/Downloads
	scp ./kafka_2.11-0.10.2.0.tgz hadoop@slave3:/home/hadoop/Downloads

	tar -zxf kafka_2.11-0.10.2.0.tgz 

2: Start the server
	- zookeeper
		bin/zookeeper-server-start.sh config/zookeeper.properties  #最新版3.4.X命令: bin/zkServer.sh start
		#最新版3.4.X不需要制定配置文件，默认使用conf/zoo.cfg配置文件,http://zookeeper.apache.org/doc/r3.4.10/zookeeperStarted.html
	
	- kafka
		bin/kafka-server-start.sh config/server.properties 
		* 后台启动：
			# ./kafka-server-start.sh ../config/server.properties 1>/dev/null 2>&1 &
			或者：
			# bin/kafka-server-start.sh config/server.properties &
			# 然后control + c
		集群:
			broker.id=1  # 不同的server不一样，必须唯一
			listeners=PLAINTEXT://172.16.49.173:9092  # 当前server的ip+port
			zookeeper.connect=localhost:2181  # 集群的zookeeper

3: Create a topic
	bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic testTopic001

	集群: 
	bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic testTopic002  #replication-factor不能大于brolers的个数

	查看所有: 
	bin/kafka-topics.sh --list --zookeeper localhost:2181 

	查看某一个:
	bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic testTopic002
	>Topic:testTopic002	PartitionCount:1	ReplicationFactor:2	Configs:
	>Topic: testTopic002	Partition: 0	Leader: 1	Replicas: 1,2	Isr: 1,2

	删除:
	bin/kafka-topics.sh --delete --zookeeper localhost:2181 --topic testTopic001

4: Send some messages
	bin/kafka-console-producer.sh --broker-list localhost:9092 --topic testTopic001
	集群: 
		./kafka-console-producer.sh --broker-list 10.199.212.113:9092,10.199.212.114:9092,10.199.212.115:9092 --topic test

5: Start a consumer
	bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic testTopic001 --from-beginning
	或者：
	bin/kafka-console-consumer.sh --zookeeper localhost:2181 --bootstrap-server localhost:9092 --topic testTopic001 --from-beginning


6: 查看zookeeper目录结构
	在zk的bin目录下
	./zkCli.sh -server 10.199.212.113:12181 #连接到zookeeper，有的版本是kafka/bin目录下：zookeeper-shell.sh localhost:2182
	ls / #查看根目录结构，没有cd，能通过逐层深入的方式查看：ls ls /brokers/topics/test/partitions

	- partition被消费到的Offset位置: 
		目录结构：/consumers/[groupId]/offsets/[topic]/[partitionId] -> long (offset)
		命令：/consumers/guest_tblog_expo/offsets/openapi_exposure/0 #说明offset是存储在consumer的
		命令返回结果：50793695368

7: 使用spring for kafka访问kafka # https://segmentfault.com/a/1190000011471181
			版本: 具体版本要和kafka server对应，最好用kafka server 10.0，kafka server 10.0之后不需要配置 advertised.host.name／advertised.port
			初衷: KafkaConsumer是线程不安全的，无法并发操作，所以spring for kafka对原生的kafka client consumer包装了一层，根据配置的spring.kafka.
	listener.concurrency来生成多个并发的KafkaMessageListenerContainer实例。

			核心类KafkaListenerAnnotationBeanPostProcessor: 扫描KafkaListener注解，然后将其信息注册到 KafkaListenerEndpointRegistrar 最终把
	endponit转化为value为MessageListenerContainer的map中，而MessageListenerContainer中有KafkaListenerContainerFactory，最终和一个支持并发
	的ConcurrentMessageListenerContainer关联上。原理：通过spring的BeanPostProcessor织入spring容器，过滤所有实例化后bean获取KafkaListener标注
	的方法；期间使用到了AopUtils和反射。

			ConcurrentMessageListenerContainer: 根据topicPartitions.length来生成多个KafkaMessageListenerContainer实例，然后每个实例都自己创建
	一个ListenerConsumer，然后自己创建一个独立的kafka consumer（kafka consumer属于 ListenerConsumer）
	    每个ListenerConsumer在线程池里头运行（线程池属于ConcurrentMessageListenerContainer），这样来实现并发。ListenerConsumer里头都有一个
	recordsToProcess队列，从原始的kafka consumer poll出来的记录会放到这个队列里头，然后有一个ListenerInvoker线程循环超时等待从recordsToProcess
	取出记录，然后交给应用程序的KafkaListener标注的方法去执行。

	问题: kafka Error reading field 'brokers':Error reading string of length 12592, only 83 bytes available
	方案: 因为版本不对，需要参考官网（https://projects.spring.io/spring-kafka/）根据kafka server的版本确定spring-kafka的版本。





http://www.cnblogs.com/likehua/p/3999538.html
Q&A
1: Q: ERROR Error when sending message to topic t1 with key: null, value: 8 bytes with error: Failed to update metadata after 60000 ms. (org.apache.kafka.clients.producer.internals.ErrorLoggingCallback)
   A: check listener value in kafka.propertie and try to change it from [listeners=PLAINTEXT://hostname:9092] to [listeners=PLAINTEXT://0.0.0.0:9092]

apache Kafka下线broker的操作: 

































