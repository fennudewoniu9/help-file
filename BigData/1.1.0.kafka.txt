一个topic可能会放在任意一个partition（分区），每个partition都有多个replica

 ■ 基本概念: 
  Broker: Kafka 集群包含一个或多个服务器，这种服务器被称为 broker。
  Topic: 每条发布到 Kafka 集群的record都有一个类别，这个类别被称为 Topic。一个Topic的record可以被写到多个partition，每一个partition
         上的record都有一个唯一的offset。物理上不同 Topic 的record分开存储，同一个Topic的record也会被生产者存储在不同分区（Partition）
         上，而逻辑上一个 Topic 的record虽然保存于一个或多个 broker 上的partition，但用户只需指定消息的 Topic 即可生产或消费数据而
         不必关心数据存于何处。
  Partition: 是物理上的概念，每个Topic包含一个或多个Partition，形成了topic级别的集群。而每个partition会根据配置的Replica的数量又形
             成一个record级别的集群。（record集群：一条record被存储在多个partition上），在server.properties中log.dirs配置。
      partition leader: Each partition has one server which acts as the "leader" and zero or more servers which act as "followers".
  Segment: partition物理上由多个segment组成。segment的命名规则有点类似B+树，即每个文件名都是一段offset的起始值，其中segment是由两种文件组成的：
          元数据物理位置00000000000000368769.index和物理偏移地址00000000000000368769.log
  Producer: 负责将那条消息发布到自己选择的哪个broker上的partiotoin上。
  Consumer: 消息消费者，向 Kafka broker 读取消息的客户端。
  Consumer Group: 每个Consumer属于一个特定的 Consumer Group（可以为每个Consumer指定group name，若不指定group name则属于默认的
                  group，一般group内的consumer的数量不能多于partition的数量）。

  消息保留时间: 可以配置，到期后的消息不管是否被消费都会被删除
  offset: offset是线性读取，但是可以被消费者重置，来回任意消费。 # 仅仅是保证Topic的一个分区顺序处理，不能保证跨分区的消息先后处理顺序。
          In fact, the only metadata retained on a per-consumer basis is the offset or position of that consumer in the log.
          # 什么日志，zk的？consumer的？还是partition服务器上的？
          zk节点数据格式: /consumers/[group_id]/offsets/[topic]/[broker_id-partition_id]-->offset_value
  publish data: 生产者负责选择which record to assign to which partition within the topic. 同时实现了rebalance
      # 选择算法
  consume data: 一个partition中的record只能被一个group中的一个consumer消费，但是一个consumer可以消费多个partition中的record。
          同一个group下的consumer数量不能多余partition（分区）的数量，否则会有consumer不能消费到消息。






■ 内部概念:
      http://www.jasongj.com/2015/08/09/KafkaColumn4/
    ■ Group ID:
      很多传统的Message Queue都会在消息被消费完后将消息删除，一方面避免重复消费，另一方面可以保证Queue的长度比较短，提高效率。而如上文所述，
      Kafka并不删除已消费的消息，为了实现传统Message Queue消息只被消费一次的语义，Kafka保证每条消息在同一个Consumer Group里只会被某一
      个Consumer消费。与传统Message Queue不同的是，Kafka还允许不同Consumer Group同时消费同一条消息，这一特性可以为消息的多元化处理提供支持。

    ■ Consumer Rebalance:
      每一个Consumer实例只会消费某一个或多个特定Partition的数据，而某个Partition的数据只会被某一个特定的Consumer实例所消费。所以如果
      consumer的个数多于partition的个数，那么会有consumer无法消费该consumer group中的topic。


      # http://www.jasongj.com/2015/04/24/KafkaColumn2/
    ■ Leader Election:
    　　引入Replication之后，同一个Partition可能会有多个Replica，而这时需要在这些Replication之间选出一个Leader，Producer和
         Consumer只与这个Leader交互，其它Replica作为Follower从Leader中复制数据。
    　　因为需要保证同一个Partition的多个Replica之间的数据一致性（其中一个宕机后其它Replica必须要能继续服务并且即不能造成数据重复也
         不能造成数据丢失）。如果没有一个Leader，所有Replica都可同时读/写数据，那就需要保证多个Replica之间互相（N×N条通路）同步数据，
         数据的一致性和有序性非常难保证，大大增加了Replication实现的复杂性，同时也增加了出现异常的几率。而引入Leader后，只有Leader负
         责数据读写，Follower只向Leader顺序Fetch数据（N条通路），系统更加简单且高效。


    ■ 消息传送机制: 针对producer和consumer两个方向的概念
      at most once: 最多一次, 如果消息未能commit成功, 下次pull时不会pull到该条消息. 
      at least once: 消息至少发送一次, 如果消息未能commit成功, 下次pull时还会pull到该条消息. 
      exactly once: 消息只会发送一次.

      - at most once: 消费者 fetch 消息,然后保存 offset,然后处理消息;当 client 保存 offset 之后,但是在消息处理过程中出现了异常,
        导致部分消息未能继续处理.那么此后"未处理"的消息将不能被 fetch 到,这就是"at most once". 
      - at least once: 消费者 fetch 消息,然后处理消息,然后保存 offset.如果消息处理成功之后,但是在保存 offset 阶段 zookeeper 
        异常导致保存操作未能执行成功,这就导致接下来再次 fetch 时可能获得上次已经处理过的消息,这就是"at least once"，原因offset没
        有及时的提交给 zookeeper，zookeeper恢复正常还是之前 offset 状态. 
      - exactly once: kafka1.0之前没有实现
      # kafka默认是 "at-least-once".(相比 at most once 而言,重复接收数据总比 丢失数据要好)
      注: 现在0.11.0已经支持exactly once了，以前不支持的实现方案：将偏移量和你要保存的状态通过JDBC事务或者JTA事务保存到数据库，失败恢
          复时从这个偏移量开始从卡夫卡中重新读取。（因为默认是at least once的；同时consumer有Simply API可以支持存储offset）。现在
          新版本直接使用Stream API即可：http://www.jdon.com/48977
          但是，一般分布式的情况下存储状态和offset并没有fetch后落地提交+是否消费的状态，且落地是去重这种方案好。类似安盈票据的方案。
          * 原理
            - produce：kafka通过幂等来解决的。这允许生产者客户端始终重试直到成功，而不会有重复的可能性(Kafka将透明地检测它们并忽略它们)
            - 


      # https://www.cnblogs.com/fxjwind/p/4972244.html
    ■ failover机制:
      - producer：一般的情况下，request.required.acks设成1（replica异步更新）在极端情况下，是有可能丢失数据的；如果可以接受较长的
        写延迟，可以选择将acks设为 –1（leader和replica之间是纯同步写），这种情况下不会丢失数据。
      - consumer：一般正常情况下，当 kafka 发生 failover 的时候，consumer 是不会读到不一致数据的。特例的情况就是，当前 leader 是
        唯一有效的 replica，其他replica都处在完全不同步状态，这样发生 leader 切换，一定是会丢数据的，并会发生 offset 不一致。
      - Zookeeper
        * Zookeeper Dead：kafka完全不工作，直到可以连上 zookeeper 为止。
        * Zookeeper Hang：kafka 的80%以上问题都是由于这个原因，主要是 zk 负载过重，zk 所在主机 cpu，memeory 或网络资源不够等，一般
          造成leader重选、partition offline等
      - Broker：leader重选等


■ 集群算法:
    (http://www.jasongj.com/2015/04/24/KafkaColumn2/)
    ■ 集群配置:
         为了更好的做负载均衡，Kafka尽量将所有的Partition均匀分配到整个集群上。一个典型的部署方式是一个Topic的Partition数量大于Broker
      的数量。同时为了提高Kafka的容错能力，也需要将同一个Partition的Replica尽量分散到不同的机器。实际上，如果所有的Replica都在同一个
      Broker上，那一旦该Broker宕机，该Partition的所有Replica都无法工作，也就达不到HA的效果。同时，如果某个Broker宕机了，需要保证它上
      面的负载可以被均匀的分配到其它幸存的所有Broker上。

    ■ Kafka分配Replica的算法如下: 
      1.将所有Broker（假设共n个Broker）和待分配的Partition排序
      2.将第i个Partition分配到第（i mod n）个Broker上
      3.将第i个Partition的第j个Replica分配到第（(i + j) mode n）个Broker上　 

    ■ Propagate消息(繁殖消息):
      　　Producer在发布消息到某个Partition时，先通过Zookeeper找到该Partition的Leader，然后无论该Topic的ReplicationFactor为多
      少（也即该Partition有多少个Replica），Producer只将该消息发送到该Partition的Leader。Leader会将该消息写入其本地Log。每个Follower
      都从Leader pull数据。这种方式上，Follower存储的数据顺序与Leader保持一致。Follower在收到该消息后，向Leader发送ACK。一旦Leader收到
      了ISR中的所有Replica的ACK，该消息就被认为已经commit了，Leader将增加HW并且向Producer发送ACK。
         为了提高性能，每个Follower在接收到数据后就立马向Leader发送ACK，而非等到数据写入Log中。因此，对于已经commit的消息，Kafka只能保证它
      被存于多个Replica的内存中，而不能保证它们被持久化到磁盘中，也就不能完全保证异常发生后该条消息一定能被Consumer消费。但考虑到这种场景非
      常少见，可以认为这种方式在性能和数据持久化上做了一个比较好的平衡。在将来的版本中，Kafka会考虑提供更高的持久性。
         Consumer读消息也是从Leader读取，只有被commit过的消息（offset低于HW的消息）才会暴露给Consumer。

         Leader会跟踪与其保持同步的Replica列表，该列表称为ISR（即in-sync Replica）。如果一个Follower宕机，或者落后太多（Follower必须能够及时
      将Leader的消息复制过来，落后太多”指Follower复制的消息落后于Leader后的条数超过预定值（该值可在$KAFKA_HOME/config/server.properties中通
      过replica.lag.max.messages配置，其默认值是4000）或者Follower超过一定时间（该值可在$KAFKA_HOME/config/server.properties中通过
      replica.lag.time.max.ms来配置，其默认值是10000）未向Leader发送fetch请求），Leader将把它从ISR中移除。




  # Zookeeper包含broker的ip地址和端口号，所存储的topics和partitions信息
■ Zookeeper上的细节: （http://blog.chinaunix.net/uid-20196318-id-2420884.html）
  1. 每个broker启动后会在zookeeper上注册一个临时的broker registry，包含broker的ip地址和端口号，所存储的topics和partitions信息。
  2. 每个consumer启动后会在zookeeper上注册一个临时的consumer registry：包含consumer所属的consumer group以及订阅的topics。
  3. 每个consumer group关联一个临时的owner registry和一个持久的offset registry。对于被订阅的每个partition包含一个owner registry，
     内容为订阅这个partition的consumer id；同时包含一个offset registry，内容为上一次订阅的offset。



■ 参考:
  Apache kafka 工作原理介绍: http://www.ibm.com/developerworks/cn/opensource/os-cn-kafka/index.html
  基本入门: http://www.cnblogs.com/likehua/p/3999538.html
  kafka消息检索: http://tech.meituan.com/kafka-fs-design-theory.html
  kafka case 命令: http://colobu.com/2015/03/12/kafka-in-practice/
  消息持久化（Message Persistence）及其缓存: http://www.oschina.net/translate/kafka-design（OS/sendfile 四次copy）
                                         http://www.cnblogs.com/tangr206/articles/2274845.html（zero-copy）
  kafka深度解析: http://www.jasongj.com/2015/01/02/Kafka%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90/
  kafka原理: http://www.infoq.com/cn/articles/kafka-analysis-part-1?cm_mc_uid=77798565572514665569150&cm_mc_sid_50200000=1466556915




■ 命令:
  查看topic信息: ./kafka-topics.sh --describe --topic  nbiz_credit_quota_option --zookeeper localhost:2181
  查看所有topic: ./kafka-topics.sh --list --zookeeper localhost:2181
  发送消息: kafka-console-producer.sh --broker-list localhost:9092 --topic nbiz_credit_quota_option



