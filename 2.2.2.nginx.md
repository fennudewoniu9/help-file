0.0: 序
    nginx的内部结构是由核心部分和一系列的功能模块所组成。这样划分是为了使得每个模块的功能相对简单，便于开发，同时也便于对系统进行功能扩展。
    #http://tengine.taobao.org/book/chapter_02.html
        * 获取客户端的真实IP模块: read_ip模块 # 需要安装，安装后重新加载即可
        * 限流、白名单: https://www.cnblogs.com/peteremperor/p/7342143.html
            - 需要用到ngx_http_limit_req_module，ngx_stream_limit_conn_module模块 
              # 基于令牌桶算法，可以方便的控制令牌速率，自定义调节限流，实现基本的限流控制。
              # 对于提供下载的网站，肯定是要进行流量控制的，例如软件下载站、视频服务等。它也可以减少一些爬虫程序或者DDOS的攻击。
            - 需要用到Ngx自带的map和geo模块
        * 限制ip并发数: http://hopestar.github.io/2013/06/08/nginx-limit-moule-note/



1: yum方式安装代理
2: CentOS安装Nginx -- yum
3: CentOS安装Nginx -- 编译
4: nginx配置详解 (HTTPS)
5: 多域名映射
6: 设置nginx只能通过域名访问
7: nginx keepalive／长度／tcp时间
8: nginx原理
9: location解析规则(修饰符-顺序)
10: 扩展(upstream)
11: 生产Nginx配置


1: yum方式安装代理
yum install tinyproxy
yum remove tinyproxy

/etc/tinyproxy/tinyproxy.conf

service tinyproxy start
service tinyproxy restart

MAC：10.199.75.12 8080

2: CentOS安装Nginx -- yum
    yum install nginx  # 安装
    yum remove nginx   # 删除
    
    service nginx start  # 启动
    或者
    cd nginx目录
    nginx -c /etc/local/nginx/nginx.conf
    
    注: 
      * 指定不同的配置文件可以启动不同的实例
      * 求实／红蝠两个结构：一台在前面域名负载，两台对应相应的实例
      * 在对应的nginx目录下执行以下命令，对应的nginx就会重新加载 nginx -s reload


3: CentOS安装Nginx -- 编译
    # http://www.nginx.cn/install
    以下所有操作都是在/usr/local/src进行的:
    yum -y install gcc automake autoconf libtool make
    yum install gcc gcc-c++

    wget http://ftp.pcre.org/pub/pcre/pcre-8.37.tar.gz
    tar -zxvf pcre-8.37.tar.gz
    cd pcre-8.34
    ./configure
    make
    make install

    wget http://prdownloads.sourceforge.net/libpng/zlib-1.2.8.tar.gz
    tar -zxvf zlib-1.2.8.tar.gz
    cd zlib-1.2.8
    ./configure
    make
    make install

    wget https://www.openssl.org/source/openssl-1.0.1t.tar.gz
    tar -zxvf openssl-1.0.1t.tar.gz

    wget http://nginx.org/download/nginx-1.4.2.tar.gz
    tar -zxvf nginx-1.4.2.tar.gz
    cd nginx-1.4.2
     
    ./configure --sbin-path=/usr/local/nginx/nginx \
    --conf-path=/usr/local/nginx/nginx.conf \
    --pid-path=/usr/local/nginx/nginx.pid \
    --with-http_ssl_module \
    --with-pcre=/opt/app/openet/oetal1/chenhe/pcre-8.37 \
    --with-zlib=/opt/app/openet/oetal1/chenhe/zlib-1.2.8 \
    --with-openssl=/opt/app/openet/oetal1/chenhe/openssl-1.0.1t
     
    make
    make install
    注: configure的参数需要参考实际安装的组件进行修改

    或者用yum的方式安装:
        sudo yum -y install openssl openssl-devel
        sudo yum -y install pcre-devel
        sudo ./configure --sbin-path=/usr/local/nginx/nginx \
        --conf-path=/usr/local/nginx/nginx.conf \
        --pid-path=/usr/local/nginx/nginx.pid \
        --with-http_ssl_module --with-http_stub_status_module
        sudo make
        sudo make install

  命令: 
    Nginx -s stop      
    # 快速关闭Nginx，可能不保存相关信息，并迅速终止web服务。                            
    Nginx -s quit      
    # 平稳关闭Nginx，保存相关信息，有安排的结束web服务。                          
    Nginx -s reload    
    # 启动一新的master,同时会向老master发送信号,老master启动新的worker,老worker不再接受请求,同时处理中的请求处理完成后再退出        
    Nginx -s reopen    
    # 重新打开日志文件。 
    Nnginx -t 
    # 查看、检查配置文件是否有问题

4: nginx配置详解 (HTTPS)
    # http://tengine.taobao.org/book/chapter_02.html
    以下是一个完整的nginx.conf内容:  # 备注：有些变量只能在http里有效，有的只能在server里有效。events等也是如此。
    # For more information on configuration, see:
    #   * Official English Documentation: http://nginx.org/en/docs/
    #   * Official Russian Documentation: http://nginx.org/ru/docs/
    
    #[注释]: nginx在运行时与具体业务功能（比如http服务或者email服务代理）无关的一些参数，比如工作进程数，运行的身份等。
    user nginx;
    worker_processes auto;  #[注释]: 从master进程forker的worker数，一般和cpu核数保持一致
    error_log /var/log/nginx/error.log;
    pid /run/nginx.pid;

    # Load dynamic modules. See /usr/share/nginx/README.dynamic.
    include /usr/share/nginx/modules/*.conf;

    events {
        worker_connections 1024;  #[注释]: 每一个worker进程支持的最大连接数，如果大于操作系统的nofile会警告，且最终生效的是nofile
    }

    http {  #[注释]: 与提供http服务相关的一些配置参数。例如：是否使用keepalive啊，是否使用gzip进行压缩等。如果是邮件服务，需要换成mail。
        log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                          '$status $body_bytes_sent "$http_referer" '
                          '"$http_user_agent" "$http_x_forwarded_for"';

        access_log  /var/log/nginx/access.log  main;

        sendfile            on;  
        # 零拷贝，Linux2.0+以后提供的比read 和write更高性能的系统接口，可以把4次拷贝／切换变2次。不过，sendfile是将in_fd的内容发送到out_fd。
        # 而in_fd不能是socket，也就是只能文件句柄。所以当Nginx是一个静态文件服务器的时候，开启SENDFILE配置项能大大提高Nginx的性能。但是当
        # Nginx是作为一个反向代理来使用的时候，SENDFILE则没什么用了，因为Nginx是反向代理的时候。in_fd就不是文件句柄而是socket，此时就不符
        # 合sendfile 函数的参数要求了。http://xiaorui.cc/2015/06/24/扯淡nginx的sendfile零拷贝的概念/
        tcp_nopush          on;  
        # 定量发送；调用tcp_cork方法，数据包不马上传送出去，等到包最大时一次性传出，有助于解决网络堵塞。使用sendfile函数时才生效；和指令
        # tcp_nodelay互斥（一个定时、一个定量）
        tcp_nodelay         on;  
        # 定时发送；禁用Nagle 算法（一种压缩算法，把一段时间内较小的包组装为更大的帧）；和指令tcp_nopush互斥（一个定时、一个定量）
        keepalive_timeout   65;  
        #[注释]: 长链接保持时间如果配置为0，则表示关掉keepalive，此时，http版本无论是1.1还是1.0，客户端的connection不管是close还是keepalive
        # ，都会强制为close。
        types_hash_max_size 2048;

        server_tokens off;       # 可以关闭在错误页面中的nginx版本数字

        include             /etc/nginx/mime.types;
        default_type        application/octet-stream;

        # Load modular configuration files from the /etc/nginx/conf.d directory.
        # See http://nginx.org/en/docs/ngx_core_module.html#include
        # for more information.
        include /etc/nginx/conf.d/*.conf;

        #[注释]: http服务上支持若干虚拟主机。每个虚拟主机对应一个server配置项，配置项里面包含该虚拟主机相关的配置。在提供mail服务的代理时，也可
        #       以建立若干server.每个server通过监听的地址来区分。
        server { 
            listen       80;
            server_name  www.fyqiushi.cn;   #server_name指令主要用于配置基于名称的虚拟主机，可以使用正则表达式
            root         /usr/share/nginx/html;

            # Load configuration files for the default server block.
            include /etc/nginx/default.d/*.conf;

            location / {  # http服务中，特定的URL对应的配置项。
                  proxy_pass http://localhost:81;
            }

            error_page 404 /404.html;
                location = /40x.html {
            }

            error_page 500 502 503 504 /50x.html;
                location = /50x.html {
            }
        }

        # Settings for a TLS enabled server.
        server {
                listen 80 default backlog=2048;  #如果硬性要求全部走https协议，这一行去除
                listen       443 ssl;            #如果硬性要求全部走https协议，这里去除ssl
                server_name  domain.com;

                #ssl on;                         #如果硬性要求全部走https协议，这里开启ssl on否则要删除改行
                ssl_certificate /etc/nginx/ssl/server.crt;
                ssl_certificate_key /etc/nginx/ssl/server.key;

                ssl_session_cache    shared:SSL:1m;
                ssl_session_timeout  5m;

                ssl_ciphers  HIGH:!aNULL:!MD5;
                ssl_prefer_server_ciphers  on;

                ssl_protocols  SSLv2 SSLv3 TLSv1.2; #ios硬性要求，上架appstore的ios产品都必须使用https协议，且使用TLS1.2以上的版本协议。

                root         /usr/share/nginx/html;

                # Load configuration files for the default server block.
                include /etc/nginx/default.d/*.conf;
        
                location / {
                }
        
                error_page 404 /404.html;
                    location = /40x.html {
                }
        
                error_page 500 502 503 504 /50x.html;
                    location = /50x.html {
                }
        }

        # mail {
        #     auth_http  127.0.0.1:80/auth.php;
        #     pop3_capabilities  "TOP"  "USER";
        #     imap_capabilities  "IMAP4rev1"  "UIDPLUS";
        # 
        #     server {
        #         listen     110;
        #         protocol   pop3;
        #         proxy      on;
        #     }
        #     server {
        #         listen      25;
        #         protocol    smtp;
        #         proxy       on;
        #         smtp_auth   login plain;
        #         xclient     off;
        #     }
        # }

        }


5: 多域名映射
    server {
        listen       80;
        server_name  www.fyqiushi.cn;
        root         /usr/share/nginx/html;

        # Load configuration files for the default server block.
        include /etc/nginx/default.d/*.conf;

        location / {
              proxy_pass http://localhost:81;
        }

        error_page 404 /404.html;
            location = /40x.html {
        }

        error_page 500 502 503 504 /50x.html;
            location = /50x.html {
        }
    }

    server {
        listen       80;
        server_name  www.hongfu-photo.com;
        root         /usr/share/nginx/html;

        # Load configuration files for the default server block.
        include /etc/nginx/default.d/*.conf;

        location / {
              proxy_pass http://localhost:82;
        }

        error_page 404 /404.html;
            location = /40x.html {
        }

        error_page 500 502 503 504 /50x.html;
            location = /50x.html {
        }
    }
    注: 修改后需要重新加载nginx.conf：nginx -s reload

    #server {
    #    listen       80 default_server;
    #    server_name  _name _;
    #    root         /usr/share/nginx/html;
    #    #return       444;
    #
    #    # Load configuration files for the default server block.
    #    include /etc/nginx/default.d/*.conf;
    #
    #    location / {
    #    }
    #
    #    error_page 404 /404.html;
    #        location = /40x.html {
    #    }
    #
    #    error_page 500 502 503 504 /50x.html;
    #        location = /50x.html {
    #    }
    }

    证书:
    # 1、首先，进入你想创建证书和私钥的目录，例如：
    cd /etc/nginx/

    # 2、创建服务器私钥，命令会让你输入一个口令：
    sudo openssl genrsa -des3 -out server.key 1024
    密码：1111

    # 3、创建签名请求的证书（CSR）：
    sudo openssl req -new -key server.key -out server.csr
    # CSR是一个证书签名请求，是客户的服务器软件所生成的一串文本字符。服务器在向CA注册的过程中首先要在WEB服务器上生成CSR，并把这串字符提供给证书认证中心。
    # https://blog.csdn.net/klarclm/article/details/7263394

    # 4、在加载SSL支持的Nginx并使用上述私钥时除去必须的口令：
    sudo cp server.key server.key.jcca
    sudo openssl rsa -in server.key.jcca -out server.key

    # 5、最后标记证书使用上述私钥和CSR：
    sudo openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt
         openssl x509 -req -in server-req.csr -out server-cert.crt -signkey server-key.key -CA public-cert.cer -CAkey private-key.key -CAcreateserial -days 3650


    自定义CA证书:
    sudo openssl genrsa -des3 -out root.key
    sudo openssl req -new -key root.key -out root.csr  #Common Name (eg, YOUR name) []: ← 此时不输入 
    openssl x509 -req -days 3650 -sha1 -extensions v3_ca -signkey root.key -in root.csr -out root.crt 

    sudo openssl genrsa -out server.key 2048 
    sudo openssl req -new -key server.key -out server.req 
    sudo openssl req -new -key server.key -out server.csr
    sudo openssl x509 -req -days 730 -sha1 -extensions v3_req -CA root.crt -CAkey root.key -CAserial root.srl -CAcreateserial -in server.csr -out server.crt

    sudo openssl genrsa -des3 -out client.key 2048
    sudo openssl req -new -key client.key -out client.csr
    sudo openssl x509 -req -days 730 -sha1 -extensions v3_req -CA root.crt -CAkey root.key -CAserial root.srl -CAcreateserial -in client.csr -out client.crt
    sudo openssl pkcs12 -export -in client.crt -inkey client.key -out client.pfx
    保存生成的文件备用，其中server.crt和server.key是配置单向SSL时需要使用的证书文件，client.crt是配置双向SSL时需要使用的证书文件，client.pfx是配置双向SSL时需要客户端安装的证书文件


    默认是没有启用ssl模块的，安装的时候需要安装先关的模块，安装Nginx https:
    sudo yum -y install openssl openssl-devel
    sudo yum -y install pcre-devel
    sudo ./configure --sbin-path=/usr/local/nginx/nginx --conf-path=/usr/local/nginx/nginx.conf --pid-path=/usr/local/nginx/nginx.pid --with-http_ssl_module --with-http_stub_status_module
    sudo make
    sudo make install
    # ./configure: error: C compiler cc is not found :::::::: yum install gcc gcc-c++ ncurses-devel perl


6: 设置nginx只能通过域名访问 
    #https://www.cnblogs.com/fangbo/archive/2011/02/21/1959855.html
    设置一个默认的域名跳转到指定的页面即可，但是用户体验不好，可以不return而是rewrite。
    server {
        listen       80 default_server;
        server_name  _name _;
        return       404;

        # Load configuration files for the default server block.
        include /etc/nginx/default.d/*.conf;

        location / {
        }

        error_page 404 /404.html;
            location = /40x.html {
        }

        error_page 500 502 503 504 /50x.html;
            location = /50x.html {
        }
    }

7: nginx keepalive／长度／tcp时间 
    # http://tengine.taobao.org/book/chapter_02.html
  * 当nginx设置了keepalive等待下一次的请求时，同时也会设置一个最大等待时间，这个时间是通过选项keepalive_timeout来配置的，如果配置为0，则表
    示关掉keepalive，此时，http版本无论是1.1还是1.0，客户端的connection不管是close还是keepalive，都会强制为close。
    
  * pipe在http1.1中引入的一种新的特性。pipeline其实就是流水线作业，它可以看作为keepalive的一种升华，因为pipeline也是基于长连接的，目的就是
    利用一个连接做多次请求。
    如果客户端要提交多个请求，对于keepalive来说，那么第二个请求，必须要等到第一个请求的响应接收完全后，才能发起，这和TCP的停止等待协议是一样的
    ，得到两个响应的时间至少为2*RTT。而对pipeline来说，客户端不必等到第一个请求处理完后，就可以马上发起第二个请求。得到两个响应的时间可能能够
    达到1*RTT。nginx是直接支持pipeline的，但是，nginx对pipeline中的多个请求的处理却不是并行的，依然是一个请求接一个请求的处理，只是在处理第
    一个请求的时候，客户端就可以发起第二个请求。这样nginx利用pipeline减少了处理完一个请求后，等待第二个请求的请求头数据的时间。
    原理: nginx在读取数据时，会将读取的数据放到一个buffer里面，所以，如果nginx在处理完前一个请求后，如果发现buffer里面还有数据，就认为剩
    下的数据是下一个请求的开始，然后就接下来处理下一个请求，否则就设置keepalive。

  * 延迟关闭。因为当出现错误码需要返回给客户端的时候，按照Nginx处理流程，所有数据会先写到writeBuffer里，所以,当在某些场景下出现tcp write 
    buffer里的数据在write()系统调用之后到close()系统调用执行之前没有发送完毕，且tcp read buffer里面还有数据没有读，close()系统调用会导致
    客户端收到RST报文且不会拿到服务端发送过来的错误信息数据。那客户端肯定会想，这服务器好霸道，动不动就reset我的连接，连个错误信息都没有。
    扩展: 调用close方法后的行为：内核会首先检查tcp的read buffer里有没有客户端发送过来的数据留在内核态没有被用户态进程读取，如果有则发送给客户
    端RST报文来关闭tcp连接、丢弃write buffer里的数据，如果没有则等待write buffer里的数据发送完毕，然后再经过正常的4次分手报文断开连接。
    #为什么有数据就发送reset，因为客户端这时候不知道出错，可能还会继续发数据过来。
    全双工的延迟关闭: 先关闭写，过一会再关闭读；所以引入了一个读超时配置项。这个时间也是nginx在关闭写之后保留socket的时间，客户端需要在这个时
    间内发送完所有的数据，否则nginx在这个时间过后会直接关掉连接。当然，nginx是支持配置是否打开lingering_close选项的，通过lingering_close
    选项来配置。 那么，我们在实际应用中，是否应该打开lingering_close呢？这个就没有固定的推荐值了，如Maxim Dounin所说，lingering_close的主
    要作用是保持更好的客户端兼容性，但是却需要消耗更多的额外资源（比如连接会一直占着）。

8: nginx原理 # http://tengine.taobao.org/book/chapter_02.html
    ![image](img/Nginx-ppt.jpg)
  * Nginx默认是使用多进程的方法进行任务处理，每个worker进程只有一个线程，单线程循环处理全部监听的事件。当然nginx也是支持多线程的方式的，只是
    我们主流的方式还是多进程的方式。例如自己在阿里云上启动的三个nginx实例，阿里云上ps -ef|grep nginx结果如下：1个worker的原因：机器是单核的
    root     21167     1  0 Nov28 ?        00:00:00 nginx: master process nginx -c /etc/nginx_hf/nginx.conf
    nginx    21168 21167  0 Nov28 ?        00:00:00 nginx: worker process
    root     21171     1  0 Nov28 ?        00:00:00 nginx: master process nginx -c /etc/nginx/nginx.conf
    nginx    21172 21171  0 Nov28 ?        00:00:00 nginx: worker process
    root     21279     1  0 Nov28 ?        00:00:00 nginx: master process nginx -c /etc/nginx_qiushi/nginx.conf
    nginx    21280 21279  0 Nov28 ?        00:00:00 nginx: worker process
    root     22560 22540  0 10:06 pts/0    00:00:00 grep --color=auto nginx
    # 注: master和worker都必须kill掉后才可以重启nginx，且kill master后worker不回自动kill
    master进程主要用来管理worker进程，包含：接收来自外界的信号，向各worker进程发送信号，监控worker进程的运行状态，当worker进程退出后(异常情
    况下)，会自动重新启动新的worker进程。而基本的网络事件，则是放在worker进程中来处理了。多个worker进程之间是对等的，他们同等竞争来自客户端的
    请求，各进程互相之间是独立的。一个请求，只可能在一个worker进程中处理，一个worker进程，不可能处理其它进程的请求。worker进程的个数是可以设置
    的，一般我们会设置与机器cpu核数一致，这里面的原因与nginx的进程模型以及事件处理模型是分不开的。worker之间通过【互斥锁】相互协调。

  * 高并发: 
    Nginx在启动后，会有一个master进程和多个worker进程，每个worker里面只有一个主线程（主要是为了充分利用CPU，更多的worker数只会导致进程来竞争
    cpu资源了，从而带来不必要的上下文切换。而且nginx为了更好的利用多核特性，提供了cpu亲缘性的绑定选项，我们可以将某一个进程绑定在某一个核上，这
    样就不会因为进程的切换带来cache的失效）。master进程主要用来管理worker进程，worker一般设置与机器cpu核数一致（通过worker_processes auto
    实现），worker之间通过互斥锁相互协调。每个worker里面只有一个主线程，何来高并发呢？nginx采用了异步非阻塞的方式来处理请求，也就是说，nginx是
    可以同时处理成千上万个请求的。apache的常用工作方式（apache也有异步非阻塞版本，但因其与自带某些模块冲突，所以不常用）。
    ![image](img/Nginx-master:work.jpg)

  * 连接数（worker_connections）: 
    每个worker进程都有一个独立的连接池（数组），对应连接数的最大上限（每个socket连接会占用掉一个fd），当fd用完后，再创建socket时，就会失败且无
    法将此连接转交给其它进程，最终会导致此tcp连接得不到处理，就中止掉了。如果该值（worker_connections）大于nofile（操作系统规定每个进程的最大
    连接数），那么实际的最大连接数是nofile，nginx会有警告。所以，一个nginx能建立的最大连接数，应该是worker_connections * worker_processes
    （HTTP请求本地资源时，如果作为反向代理：worker_connections * worker_processes/2，因为每个并发会建立与客户端的连接和与后端服务的连接，会
    占用两个连接）。ngx_accept_disabled变量--降低中止TCP连接概率的算法（竞争互斥锁的前置判断）：worker_connections／8 - 空余连接数，当小于
    0时候竞争互斥锁，当大于0时放弃竞争，同时ngx_accept_disabled - 1。这样，nginx就控制了多进程间连接的平衡了。请求过来-获取竞争锁阶段实现：竞
    争阶段会引起惊群现象，但由于有accept_mutex互斥锁机制，避免了CPU资源的浪费。

9: location解析规则(修饰符-顺序)
    # proxy_pass详解：http://ftlynx.blog.51cto.com/2833447/839607                                                                                                    
    下面四种情况分别用http://192.168.1.4/proxy/test.html 进行访问。                                                                                               
        第一种:                                                                                                
            location  /proxy/ {                                                                                         
                      proxy_pass http://127.0.0.1:81/;                                                                                          
            }                                                                                           
            # 会被代理到http://127.0.0.1:81/test.html 这个url                                                                                            

        第二咱(相对于第一种，最后少一个 /):
            location  /proxy/ {
                      proxy_pass http://127.0.0.1:81;
            }                                                                                           
            # 会被代理到http://127.0.0.1:81/proxy/test.html 这个url                                                                                          

        第三种:                                                                                                
            location  /proxy/ {                                                                                         
                      proxy_pass http://127.0.0.1:81/ftlynx/;                                                                                           
            }                                                                                           
            # 会被代理到http://127.0.0.1:81/ftlynx/test.html 这个url                                                                                         

        第四种情况(相对于第三种，最后少一个 / ):                                                                                             
            location  /proxy/ {                                                                                         
                      proxy_pass http://127.0.0.1:81/ftlynx;                                                                                            
            }                                                                                           
            # 会被代理到http://127.0.0.1:81/ftlynxtest.html 这个url                                                                                           

        总结:                       
            第一步：根据location把原url删除一样的部分得到A：http://192.168.1.4和B：test.html
            第二步：proxy_pass如果以／结尾，直接把B跟在proxy_pass后面；proxy_pass如果不以／结尾，把location的部分放在A和B中间

    修饰符: [=|~|~*|^~|/] [nginx分正则匹配和普通匹配（又称前缀匹配）] #https://juejin.im/post/5ce5e1f65188254159084141
        = 表示精确匹配
        ~ 表示区分大小写的正则匹配（顾名思义^~表示非正则匹配，^表示非）
        ~* 表示不区分大小写的正则匹配
        ^~ 表示uri以某个常规字符串开头，立刻停止后续的正则搜索。nginx不对url做编码，因此请求为/static/20%/aa，可以被规则^~ /static/ /aa匹配到（注意是空格）
        !~ 和 !~* 分别为区分大小写不匹配及不区分大小写不匹配的正则
        / 通用匹配，任何请求都会匹配到           

    修饰符查找的顺序及优先级:
        * 1.精确匹配 = （立刻停止后续的正则搜索）
        * 2.前缀匹配 ^~（立刻停止后续的正则搜索）
        * 3.正则匹配按文件中顺序 ~或~*
        * 4.匹配不带任何修饰的前缀匹配
        换言之：前缀匹配下，返回最长匹配的 location，与 location 所在位置顺序无关；正则匹配是使用文件中的顺序，找到返回，和顺序有关。前缀和正则同时存在时，正则优先级
               高，但精确和前缀停止匹配存在时还是精确和前缀停止匹配高。具体可参考：https://juejin.im/post/5ce5e1f65188254159084141



10: 扩展(upstream)
    ngx_stream_upstream_module: # used to define groups of servers that can be referenced by the proxy_pass directive.端口映射到群组。

    stream {
        resolver 10.0.0.1; # monitors changes of the IP addresses that correspond to a domain name of the server, and automatically
        # modifies the upstream configuration without the need of restarting nginx. The server group must reside in the shared memory.

        upstream backend1 {
        # upstream模块实现反向代理的功能，将真正的请求转发到后端服务器上，并从后端服务器上读取响应，发回客户端。upstream模块是一种特殊的handler，
        # 只不过响应内容不是真正由自己产生的，而是从后端服务器上读取的。
            # upstream还可以为每个设备设置状态值，这些状态值的含义分别如下：
            #   down 表示单前的server暂时不参与负载.
            #   weight 默认为1.weight越大，负载的权重就越大。
            #   max_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误.
            #   fail_timeout: max_fails次失败后，暂停的时间。
            #   backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。
            #   ip_hash;   #每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。
            #   fair;     #按后端服务器的响应时间来分配请求，响应时间短的优先分配。与weight分配策略类似。

            ip_hash; 
            server 10.0.0.11:9090 down; 
            server 10.0.0.11:8080 weight=2 max_fails=2 fail_timeout=30s; 
            server 10.0.0.11:6060; 
            server 10.0.0.11:7070 backup; 
        }

        server {
            listen 8080;

            location /{
                proxy_next_upstream    http_500 http_502  error  timeout  invalid_header;
                proxy_set_header    Host $host;
                proxy_set_header    X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_pass backend1;  #proxy_pass  http://backend1;
                expires             0;
            }
        }
    }


11: 生产Nginx配置
    user  nginx;

    worker_processes 4;

    error_log  /app/data/logs/nginx/nginx_error.log  crit;
    pid        /var/run/nginx.pid;


    #Specifies the value for maximum file descriptors that can be opened by this process.
    worker_rlimit_nofile 51200;

    events {
        use epoll;
        worker_connections 50000;
        multi_accept on;
    }

    http {
        log_format  main  '$http_x_forwarded_for - $remote_user [$time_local] "$request" '
             '$status $body_bytes_sent "$http_referer" '
             '"$http_user_agent"  $request_time $remote_addr'  '[$upstream_status  $upstream_addr $upstream_response_time]';

        include       /etc/nginx/mime.types;
        default_type  application/octet-stream;

        server_names_hash_bucket_size 128;
        client_header_buffer_size 32k;
        large_client_header_buffers 4 32k;
        client_max_body_size 50m;

        sendfile   on;
        tcp_nopush on;

        keepalive_timeout 60;

        tcp_nodelay on;

        fastcgi_connect_timeout 300;
        fastcgi_send_timeout 300;
        fastcgi_read_timeout 300;
        fastcgi_buffer_size 64k;
        fastcgi_buffers 4 64k;
        fastcgi_busy_buffers_size 128k;
        fastcgi_temp_file_write_size 256k;

        gzip on;
        gzip_min_length  1k;
        gzip_buffers     4 16k;
        gzip_http_version 1.1;
        gzip_comp_level 2;
        gzip_types  text/plain application/javascript application/x-javascript text/javascript text/css application/xml application/xml+rss;
        gzip_vary on;
        gzip_proxied   expired no-cache no-store private auth;
        gzip_disable   "MSIE [1-6]\.";

        #limit_conn_zone $binary_remote_addr zone=perip:10m;
        ##If enable limit_conn_zone,add "limit_conn perip 10;" to server section.

        server_tokens off;
        access_log off;
        geo $http_x_forwarded_for $ip_blacklist {
        default 0;
        include ip_black.conf;
        }

        lua_package_path "/app/data/nginx/ngx_extend/thrid/?.lua;/app/data/nginx/ngx_extend/lua/?.lua;;";
        lua_package_cpath "/app/data/nginx/ngx_extend/thrid/lib/?.so;;";
        lua_shared_dict limit_req_store 100m;

        include /etc/nginx/conf.d/*.conf;
    }


